import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import random

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio Pro", page_icon="ğŸš€", layout="wide")

# --- 2. KHá»I Táº O SESSION STATE ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""
if "is_auto_running" not in st.session_state: st.session_state.is_auto_running = False
if "loop_count" not in st.session_state: st.session_state.loop_count = 0

# --- 3. TIÃŠU CHUáº¨N Váº¬N HÃ€NH (STRICT RULES) ---
STRICT_RULES = """
Báº¢N TIN Cáº¬Y TUYá»†T Äá»I (ANTI-HALLUCINATION):
1. CHá»ˆ trÃ­ch xuáº¥t thÃ´ng tin cÃ³ trong tá»‡p nguá»“n. 
2. Cáº¤M bá»‹a Ä‘áº·t tÃªn ngÆ°á»i, chá»©c vá»¥ hoáº·c má»‘c thá»i gian.
3. Báº®T BUá»˜C trÃ­ch dáº«n má»‘c thá»i gian dáº¡ng [mm:ss] cho má»—i Ä‘oáº¡n gá»¡ bÄƒng.
4. Náº¿u thÃ´ng tin khÃ´ng rÃµ, ghi 'Dá»¯ liá»‡u nhiá»…u/KhÃ´ng xÃ¡c Ä‘á»‹nh'.
5. Giá»¯ nguyÃªn cÃ¡c luá»“ng Ã½ kiáº¿n trÃ¡i chiá»u (Debate), khÃ´ng tá»± Ã½ há»£p nháº¥t.
"""

# --- 4. HÃ€M Há»– TRá»¢ & CÆ  CHáº¾ RETRY ---
def configure_genai(user_key=None):
    api_key = user_key or ""
    if not api_key:
        try:
            if "GOOGLE_API_KEY" in st.secrets: api_key = st.secrets["GOOGLE_API_KEY"]
            elif "SYSTEM_KEYS" in st.secrets:
                keys = st.secrets["SYSTEM_KEYS"]
                api_key = random.choice(keys) if isinstance(keys, list) else keys
        except: pass
    
    if api_key:
        genai.configure(api_key=api_key)
        return True
    return False

async def safe_generate_content(model, contents, config):
    """Triá»ƒn khai Exponential Backoff (Thá»­ láº¡i 5 láº§n)"""
    for i in range(5):
        try:
            response = model.generate_content(contents, generation_config=config)
            return response
        except Exception as e:
            if i == 4: raise e
            wait_time = (2 ** i) + random.random()
            time.sleep(wait_time)
    return None

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('BÃO CÃO PHÃ‚N TÃCH CHUYÃŠN SÃ‚U', 0)
    clean_content = content.replace("```markdown", "").replace("```", "")
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- 5. GIAO DIá»†N CHÃNH ---
def main():
    try:
        st.markdown(f"""<h1 style='text-align: center; color: #2563eb;'>Universal AI Studio (Pro v3.0)</h1>""", unsafe_allow_html=True)
        
        with st.sidebar:
            st.header("ğŸ› ï¸ ÄIá»€U KHIá»‚N")
            main_mode = st.radio("Cháº¿ Ä‘á»™:", ("ğŸ“ Gá»¡ bÄƒng (Transcript)", "ğŸ“Š PhÃ¢n tÃ­ch (Analytics)"))
            
            st.divider()
            
            if main_mode.startswith("ğŸ“Š"):
                st.subheader("BÃ¡o cÃ¡o Ä‘áº§u ra:")
                opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t Dashboard", True)
                opt_action = st.checkbox("âœ… Káº¿ hoáº¡ch hÃ nh Ä‘á»™ng", True)
                opt_mindmap = st.checkbox("ğŸ§  SÆ¡ Ä‘á»“ tÆ° duy (Mindmap)", True)
                opt_debate = st.checkbox("âš–ï¸ Luá»“ng Ã½ kiáº¿n trÃ¡i chiá»u", True)
            else:
                auto_continue = st.checkbox("Tá»± Ä‘á»™ng ná»‘i Ä‘oáº¡n thÃ´ng minh", value=True)
            
            st.divider()
            with st.expander("ğŸ”‘ Cáº¥u hÃ¬nh há»‡ thá»‘ng"):
                user_key = st.text_input("API Key cÃ¡ nhÃ¢n:", type="password")
                if configure_genai(user_key):
                    st.success("Há»‡ thá»‘ng: Sáºµn sÃ ng")
                    # Máº·c Ä‘á»‹nh dÃ¹ng engine 3.0 Flash (ID: gemini-2.5-flash-preview-09-2025)
                    model_version = "gemini-2.5-flash-preview-09-2025"
                else: st.error("Lá»—i: ChÆ°a cÃ³ API Key")

            if st.button("ğŸ”„ LÃ m má»›i dá»¯ liá»‡u", use_container_width=True):
                st.session_state.clear(); st.rerun()

        tab_work, tab_chat = st.tabs(["ğŸ“‚ Trung tÃ¢m Xá»­ lÃ½", "ğŸ’¬ Chat vá»›i TÃ i liá»‡u"])

        with tab_work:
            if not st.session_state.is_auto_running:
                col_up, col_rec = st.columns(2)
                with col_up:
                    up_files = st.file_uploader("KÃ©o tháº£ file (Audio/PDF/Docx)", accept_multiple_files=True)
                with col_rec:
                    st.write("Ghi Ã¢m trá»±c tiáº¿p:")
                    audio_bytes = audio_recorder(text="Báº¥m Ä‘á»ƒ ghi Ã¢m", pause_threshold=2.0)

                if st.button("ğŸš€ KÃCH HOáº T Xá»¬ LÃ", type="primary", use_container_width=True):
                    temp_paths = []
                    if up_files:
                        for f in up_files:
                            ext = os.path.splitext(f.name)[1] or ".txt"
                            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                                tmp.write(f.getvalue()); temp_paths.append(tmp.name)
                    if audio_bytes:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                            tmp.write(audio_bytes); temp_paths.append(tmp.name)
                    
                    if not temp_paths:
                        st.warning("ThÃ´ng bÃ¡o: ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘áº§u vÃ o.")
                    else:
                        with st.spinner("Äang táº£i dá»¯ liá»‡u lÃªn Gemini Cloud..."):
                            try:
                                g_files = [upload_to_gemini(p) for p in temp_paths]
                                st.session_state.gemini_files = g_files
                                
                                gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.1)
                                model = genai.GenerativeModel(model_version)

                                if main_mode.startswith("ğŸ“"):
                                    prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: Gá»¡ bÄƒng nguyÃªn vÄƒn 100%. Äá»‹nh danh ngÆ°á»i nÃ³i lÃ  'Diá»…n giáº£ A', 'Diá»…n giáº£ B'..."
                                    if auto_continue:
                                        st.session_state.is_auto_running = True
                                        st.session_state.loop_count = 1
                                else:
                                    prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch chuyÃªn sÃ¢u dá»¯ liá»‡u.\n"
                                    if opt_summary: prompt += "## ğŸ“‹ TÃ“M Táº®T DASHBOARD (Dáº¡ng Ä‘á»‘i thoáº¡i)\n"
                                    if opt_action: prompt += "## âœ… Káº¾ HOáº CH HÃ€NH Äá»˜NG (Ai - LÃ m gÃ¬ - Deadline)\n"
                                    if opt_debate: prompt += "## âš–ï¸ PHÃ‚N TÃCH TRANH LUáº¬N (CÃ¡c Ã½ kiáº¿n trÃ¡i chiá»u)\n"
                                    if opt_mindmap: prompt += "## ğŸ§  MÃƒ SÆ  Äá»’ (Mermaid code)\n"

                                response = model.generate_content([prompt] + g_files, generation_config=gen_config)
                                st.session_state.analysis_result = response.text
                                st.rerun()
                            except Exception as e: st.error(f"Lá»—i API: {e}")

            # HIá»‚N THá»Š Káº¾T QUáº¢ THEO STYLE COO
            if st.session_state.analysis_result:
                st.divider()
                res = st.session_state.analysis_result
                
                # Biá»ƒu Ä‘á»“ Mindmap
                if "```mermaid" in res:
                    with st.container():
                        st.subheader("ğŸ§  SÆ¡ Ä‘á»“ TÆ° duy Há»‡ thá»‘ng")
                        try:
                            m_code = res.split("```mermaid")[1].split("```")[0]
                            st_mermaid(m_code, height=450)
                        except: st.info("SÆ¡ Ä‘á»“ Ä‘ang Ä‘Æ°á»£c xá»­ lÃ½...")

                # Ná»™i dung chi tiáº¿t
                sections = res.split("## ")
                for s in sections:
                    if not s.strip(): continue
                    lines = s.split("\n")
                    header = lines[0].strip()
                    with st.expander(f"ğŸ” {header}", expanded=True):
                        st.markdown("\n".join(lines[1:]))

                # Xuáº¥t bÃ¡o cÃ¡o
                doc = create_docx(res)
                with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as doc_io:
                    doc.save(doc_io.name)
                    with open(doc_io.name, "rb") as f:
                        st.download_button("ğŸ“¥ Táº¢I BÃO CÃO (.DOCX)", f, "Bao_Cao_Universal_AI.docx", type="primary")
                
                # LOGIC Tá»° Äá»˜NG CHáº Y TIáº¾P (LOOP)
                if st.session_state.is_auto_running and main_mode.startswith("ğŸ“"):
                    st.info(f"ğŸ”„ Äang nghe tiáº¿p Ä‘oáº¡n sau (VÃ²ng {st.session_state.loop_count})...")
                    if st.button("ğŸ›‘ Dá»ªNG Tá»° Äá»˜NG"):
                        st.session_state.is_auto_running = False; st.rerun()
                    
                    time.sleep(2) # Chá» Ä‘á»ƒ user ká»‹p nhÃ¬n
                    try:
                        last_anchor = res[-600:]
                        c_prompt = f"CONTEXT: ÄÃ£ gá»¡ bÄƒng Ä‘áº¿n Ä‘oáº¡n: '{last_anchor}'. NHIá»†M Vá»¤: Viáº¿t tiáº¿p nguyÃªn vÄƒn pháº§n cÃ²n láº¡i tá»« file. KHÃ”NG láº·p láº¡i má» neo."
                        model = genai.GenerativeModel(model_version)
                        c_res = model.generate_content([c_prompt] + st.session_state.gemini_files)
                        
                        if len(c_res.text) < 30 or "káº¿t thÃºc" in c_res.text.lower():
                            st.session_state.is_auto_running = False
                            st.success("Há»‡ thá»‘ng: ÄÃ£ hoÃ n táº¥t gá»¡ bÄƒng toÃ n bá»™ file.")
                        else:
                            st.session_state.analysis_result += "\n\n" + c_res.text
                            st.session_state.loop_count += 1
                            st.rerun()
                    except: st.session_state.is_auto_running = False

        with tab_chat:
            st.header("ğŸ’¬ Trá»£ lÃ½ TÃ i liá»‡u")
            if st.session_state.gemini_files:
                for m in st.session_state.chat_history:
                    with st.chat_message(m["role"]): st.markdown(m["content"])
                if inp := st.chat_input("Há»i báº¥t cá»© Ä‘iá»u gÃ¬ vá» file Ä‘Ã£ upload..."):
                    st.session_state.chat_history.append({"role": "user", "content": inp})
                    with st.chat_message("user"): st.markdown(inp)
                    with st.chat_message("assistant"):
                        m = genai.GenerativeModel(model_version)
                        r = m.generate_content(st.session_state.gemini_files + [f"Dá»±a vÃ o file, hÃ£y tráº£ lá»i: {inp}"])
                        st.markdown(r.text)
                        st.session_state.chat_history.append({"role": "assistant", "content": r.text})
            else: st.info("Vui lÃ²ng xá»­ lÃ½ file á»Ÿ tab 'Xá»­ lÃ½' trÆ°á»›c khi chat.")

    except Exception as e:
        st.error(f"Há»‡ thá»‘ng gáº·p sá»± cá»‘: {e}")

if __name__ == "__main__":
    main()
