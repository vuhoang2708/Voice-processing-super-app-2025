import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Universal AI Studio", page_icon="üåå", layout="wide")
st.markdown("""<style>.stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold;}</style>""", unsafe_allow_html=True)

# --- QU·∫¢N L√ù TR·∫†NG TH√ÅI ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""

# --- H√ÄM H·ªñ TR·ª¢ ---
def configure_genai():
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        return True
    except:
        st.error("üö® Ch∆∞a nh·∫≠p API Key trong Secrets!")
        return False

def get_real_models():
    try:
        models = genai.list_models()
        valid_list = []
        for m in models:
            if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name:
                valid_list.append(m.name)
        valid_list.sort(reverse=True) 
        return valid_list
    except:
        return ["models/gemini-1.5-flash", "models/gemini-1.5-pro"]

def get_mime_type(file_path):
    # T·ª± ƒë·ªông x√°c ƒë·ªãnh lo·∫°i file ƒë·ªÉ g·ª≠i cho Google
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type: return mime_type
    # Fallback th·ªß c√¥ng n·∫øu th∆∞ vi·ªán kh√¥ng nh·∫≠n ra
    ext = os.path.splitext(file_path)[1].lower()
    if ext == '.pdf': return 'application/pdf'
    if ext == '.txt': return 'text/plain'
    if ext == '.md': return 'text/md'
    if ext == '.csv': return 'text/csv'
    if ext in ['.mp3', '.wav', '.m4a']: return 'audio/mp3'
    return 'application/octet-stream'

def upload_to_gemini(path):
    mime = get_mime_type(path)
    file = genai.upload_file(path, mime_type=mime)
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('UNIVERSAL AI REPORT', 0)
    for line in content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- MAIN APP ---
def main():
    st.title("üåå Universal AI Studio (Audio + PDF + Text)")
    if not configure_genai(): return

    # --- SIDEBAR ---
    with st.sidebar:
        st.header("üß† C·∫•u h√¨nh AI")
        
        # 1. Ch·ªçn Model
        with st.spinner("ƒêang ƒë·ªìng b·ªô Model..."):
            real_models = get_real_models()
        if not real_models: st.error("L·ªói API Key"); return
        model_version = st.selectbox("Engine:", real_models)

        # 2. Ch·ªçn ƒë·ªô chi ti·∫øt (T√çNH NƒÇNG M·ªöI)
        detail_level = st.select_slider(
            "ƒê·ªô chi ti·∫øt ƒë·∫ßu ra:",
            options=["Ng·∫Øn g·ªçn (Brief)", "V·ª´a ph·∫£i (Standard)", "Chi ti·∫øt s√¢u (Deep Dive)"],
            value="V·ª´a ph·∫£i (Standard)"
        )

        st.divider()
        st.header("üõ†Ô∏è B·ªô C√¥ng C·ª• (Weapons)")
        
        st.markdown("**1. Ph√¢n t√≠ch c·ªët l√µi**")
        opt_summary = st.checkbox("T√≥m t·∫Øt & Action Items", True)
        opt_process = st.checkbox("Tr√≠ch xu·∫•t Quy tr√¨nh (Step-by-step)", False) # H·ªìi sinh
        opt_prosody = st.checkbox("Ph√¢n t√≠ch C·∫£m x√∫c/Th√°i ƒë·ªô", False) # H·ªìi sinh
        opt_gossip = st.checkbox("Ch·∫ø ƒë·ªô 'B√† t√°m' (Gossip)", False) # H·ªìi sinh
        
        st.markdown("**2. S√°ng t·∫°o n·ªôi dung**")
        opt_audio_script = st.checkbox("Podcast Script", False)
        opt_video_script = st.checkbox("Video Script", False)
        opt_mindmap = st.checkbox("Mindmap (S∆° ƒë·ªì t∆∞ duy)", True)
        
        st.markdown("**3. H·ªçc t·∫≠p & D·ªØ li·ªáu**")
        opt_report = st.checkbox("B√°o c√°o chuy√™n s√¢u (Formal)", False)
        opt_quiz = st.checkbox("Quiz / Flashcards", False)
        opt_data = st.checkbox("B·∫£ng d·ªØ li·ªáu / Slide Outline", False)

        st.divider()
        if st.button("üóëÔ∏è Reset App"):
            st.session_state.clear()
            st.rerun()

    # --- GIAO DI·ªÜN TAB ---
    tab1, tab2 = st.tabs(["üìÇ Upload & Ph√¢n t√≠ch", "üí¨ Chat ƒêa ph∆∞∆°ng th·ª©c"])

    # === TAB 1 ===
    with tab1:
        col_up, col_rec = st.columns(2)
        files_to_process = []
        
        with col_up:
            st.subheader("1. Upload ƒêa nƒÉng")
            # H·ªó tr·ª£ th√™m pdf, txt, md, csv
            uploaded_files = st.file_uploader(
                "Ch·ªçn file (Audio, PDF, Text...)", 
                type=['mp3', 'wav', 'm4a', 'pdf', 'txt', 'md', 'csv'], 
                accept_multiple_files=True
            )
        
        with col_rec:
            st.subheader("2. Ghi √¢m tr·ª±c ti·∫øp")
            audio_bytes = audio_recorder()

        if st.button("üî• K√çCH HO·∫†T PH√ÇN T√çCH", type="primary"):
            # Gom file
            temp_paths = []
            if uploaded_files:
                for up_file in uploaded_files:
                    # L·∫•y ƒëu√¥i file g·ªëc ƒë·ªÉ Gemini nh·∫≠n di·ªán ƒë√∫ng (quan tr·ªçng cho PDF)
                    file_ext = os.path.splitext(up_file.name)[1]
                    if not file_ext: file_ext = ".txt"
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
                        tmp.write(up_file.getvalue())
                        temp_paths.append(tmp.name)
            
            if audio_bytes:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_bytes)
                    temp_paths.append(tmp.name)
            
            if not temp_paths:
                st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·∫ßu v√†o!")
            else:
                with st.spinner(f"ƒêang x·ª≠ l√Ω {len(temp_paths)} file v·ªõi ƒë·ªô chi ti·∫øt: {detail_level}..."):
                    try:
                        gemini_files_objs = []
                        for path in temp_paths:
                            g_file = upload_to_gemini(path)
                            gemini_files_objs.append(g_file)
                            os.remove(path)
                        
                        st.session_state.gemini_files = gemini_files_objs
                        
                        # Prompt x√¢y d·ª±ng theo y√™u c·∫ßu
                        prompt = f"""
                        B·∫°n l√† tr·ª£ l√Ω AI cao c·∫•p. H√£y ph√¢n t√≠ch c√°c t√†i li·ªáu/file ghi √¢m ƒë∆∞·ª£c cung c·∫•p.
                        
                        Y√äU C·∫¶U CHUNG:
                        - ƒê·ªô chi ti·∫øt: {detail_level}.
                        - Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát chuy√™n nghi·ªáp (tr·ª´ khi y√™u c·∫ßu kh√°c).
                        
                        H√ÉY TH·ª∞C HI·ªÜN C√ÅC NHI·ªÜM V·ª§ SAU (Ch·ªâ m·ª•c ƒë∆∞·ª£c ch·ªçn):
                        """
                        
                        if opt_summary: prompt += "\n- T√ìM T·∫ÆT & ACTION ITEMS: T√≥m t·∫Øt √Ω ch√≠nh v√† li·ªát k√™ h√†nh ƒë·ªông c·∫ßn l√†m (Ai, l√†m g√¨, deadline).\n"
                        if opt_process: prompt += "\n- QUY TR√åNH (PROCESS): Tr√≠ch xu·∫•t c√°c b∆∞·ªõc th·ª±c hi·ªán d·∫°ng Step-by-step (B∆∞·ªõc 1, B∆∞·ªõc 2...).\n"
                        if opt_prosody: prompt += "\n- C·∫¢M X√öC & TH√ÅI ƒê·ªò: Ph√¢n t√≠ch ng·ªØ ƒëi·ªáu, s·ª± do d·ª±, cƒÉng th·∫≥ng ho·∫∑c ƒë·ªìng thu·∫≠n c·ªßa ng∆∞·ªùi n√≥i (n·∫øu l√† √¢m thanh).\n"
                        if opt_gossip: prompt += "\n- CH·∫æ ƒê·ªò B√Ä T√ÅM: K·ªÉ l·∫°i n·ªôi dung theo phong c√°ch h√†i h∆∞·ªõc, th√¢n m·∫≠t, d√πng ng√¥n ng·ªØ ƒë·ªùi th∆∞·ªùng.\n"
                        
                        if opt_audio_script: prompt += "\n- PODCAST SCRIPT: K·ªãch b·∫£n ƒë·ªëi tho·∫°i Host/Guest h·∫•p d·∫´n.\n"
                        if opt_video_script: prompt += "\n- VIDEO SCRIPT: K·ªãch b·∫£n video 2 c·ªôt (H√¨nh ·∫£nh - √Çm thanh).\n"
                        if opt_mindmap: prompt += "\n- MINDMAP: M√£ code Mermaid.js (graph TD) trong block ```mermaid```.\n"
                        
                        if opt_report: prompt += "\n- B√ÅO C√ÅO CHUY√äN S√ÇU: VƒÉn phong h√†nh ch√≠nh/h·ªçc thu·∫≠t, c·∫•u tr√∫c ch·∫∑t ch·∫Ω.\n"
                        if opt_quiz: prompt += "\n- QUIZ & FLASHCARDS: T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám v√† th·∫ª ghi nh·ªõ.\n"
                        if opt_data: prompt += "\n- D·ªÆ LI·ªÜU: Tr√≠ch xu·∫•t b·∫£ng bi·ªÉu (Markdown Table) v√† d√†n √Ω Slide.\n"

                        model = genai.GenerativeModel(model_version)
                        response = model.generate_content([prompt] + gemini_files_objs)
                        
                        st.session_state.analysis_result = response.text
                        st.success("‚úÖ X·ª≠ l√Ω xong!")
                    except Exception as e:
                        st.error(f"L·ªói: {e}")

        if st.session_state.analysis_result:
            st.divider()
            content = st.session_state.analysis_result
            if "```mermaid" in content:
                st.subheader("üß† B·∫£n ƒë·ªì t∆∞ duy")
                try:
                    mermaid_code = content.split("```mermaid")[1].split("```")[0]
                    st_mermaid(mermaid_code, height=500)
                except: pass
            st.markdown(content)
            
            doc = create_docx(content)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("üì• T·∫£i b√°o c√°o (.docx)", f, "Universal_Report.docx")
            os.remove(doc_io.name)

    # === TAB 2 ===
    with tab2:
        st.header("üí¨ Chat v·ªõi D·ªØ li·ªáu (Audio/PDF/Text)")
        if not st.session_state.gemini_files:
            st.info("üëà Vui l√≤ng Upload file ·ªü Tab 1 tr∆∞·ªõc.")
        else:
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if user_input := st.chat_input("H·ªèi chi ti·∫øt v·ªÅ t√†i li·ªáu/cu·ªôc h·ªçp..."):
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                with st.chat_message("user"): st.markdown(user_input)
                with st.chat_message("assistant"):
                    with st.spinner("ƒêang suy nghƒ©..."):
                        try:
                            # Chat d√πng model ƒëang ch·ªçn
                            chat_model = genai.GenerativeModel(model_version)
                            response = chat_model.generate_content(
                                st.session_state.gemini_files + 
                                [f"Y√™u c·∫ßu: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n c√°c file ƒë√£ cung c·∫•p. ƒê·ªô chi ti·∫øt: {detail_level}. C√¢u h·ªèi: {user_input}"]
                            )
                            st.markdown(response.text)
                            st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                        except Exception as e: st.error(f"L·ªói chat: {e}")

if __name__ == "__main__":
    main()
