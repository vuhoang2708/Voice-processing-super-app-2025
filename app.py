import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio Pro", page_icon="ğŸŒŒ", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: linear-gradient(to right, #4b6cb7, #182848); color: white;}
    .stExpander {border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px;}
</style>
""", unsafe_allow_html=True)

# --- QUáº¢N LÃ TRáº NG THÃI ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""

# --- HÃ€M Há»– TRá»¢ ---
def configure_genai():
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        return True
    except:
        st.error("ğŸš¨ ChÆ°a nháº­p API Key trong Secrets!")
        return False

def get_real_models():
    try:
        models = genai.list_models()
        valid_list = []
        for m in models:
            if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name:
                valid_list.append(m.name)
        valid_list.sort(reverse=True) 
        return valid_list
    except:
        return ["models/gemini-1.5-flash", "models/gemini-1.5-pro"]

def get_mime_type(file_path):
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type: return mime_type
    ext = os.path.splitext(file_path)[1].lower()
    if ext == '.pdf': return 'application/pdf'
    if ext == '.txt': return 'text/plain'
    if ext == '.md': return 'text/md'
    if ext == '.csv': return 'text/csv'
    if ext in ['.mp3', '.wav', '.m4a']: return 'audio/mp3'
    return 'application/octet-stream'

def upload_to_gemini(path):
    mime = get_mime_type(path)
    file = genai.upload_file(path, mime_type=mime)
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('UNIVERSAL AI REPORT', 0)
    for line in content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- MAIN APP ---
def main():
    st.title("ğŸŒŒ Universal AI Studio (Pro Max)")
    if not configure_genai(): return

    # --- SIDEBAR ---
    with st.sidebar:
        st.header("ğŸ§  Cáº¥u hÃ¬nh AI")
        with st.spinner("Äang Ä‘á»“ng bá»™ Model..."):
            real_models = get_real_models()
        if not real_models: st.error("Lá»—i API Key"); return
        model_version = st.selectbox("Engine:", real_models)

        detail_level = st.select_slider("Äá»™ chi tiáº¿t:", options=["Ngáº¯n gá»n", "TiÃªu chuáº©n", "Chi tiáº¿t sÃ¢u"], value="TiÃªu chuáº©n")

        st.divider()
        st.header("ğŸ› ï¸ KHO VÅ¨ KHÃ (Chá»n mÃ³n)")
        
        # NHÃ“M 1: Cá»T LÃ•I (ORIGINAL FEATURES)
        st.markdown("### 1. PhÃ¢n tÃ­ch Cá»‘t lÃµi")
        opt_summary = st.checkbox("ğŸ“ TÃ³m táº¯t & Action Items", True)
        opt_process = st.checkbox("ğŸ”„ TrÃ­ch xuáº¥t Quy trÃ¬nh (Step-by-step)", False)
        opt_prosody = st.checkbox("ğŸ­ PhÃ¢n tÃ­ch Cáº£m xÃºc/ThÃ¡i Ä‘á»™", False)
        opt_gossip = st.checkbox("â˜• Cháº¿ Ä‘á»™ 'BÃ  tÃ¡m' (Gossip)", False)

        # NHÃ“M 2: NOTEBOOKLM NGHE NHÃŒN
        st.markdown("### 2. SÃ¡ng táº¡o Nghe/NhÃ¬n")
        opt_audio_script = st.checkbox("ğŸ™ï¸ Podcast Script (Host/Guest)", False)
        opt_video_script = st.checkbox("ğŸ¬ Video Script (2 cá»™t)", False)
        opt_mindmap = st.checkbox("ğŸ§  Mindmap (SÆ¡ Ä‘á»“ tÆ° duy)", True)

        # NHÃ“M 3: Há»ŒC Táº¬P & NGHIÃŠN Cá»¨U
        st.markdown("### 3. Há»c táº­p & NghiÃªn cá»©u")
        opt_report = st.checkbox("ğŸ“‘ BÃ¡o cÃ¡o chuyÃªn sÃ¢u (Formal)", False)
        opt_briefing = st.checkbox("ğŸ“„ Briefing Doc (TÃ³m lÆ°á»£c)", False)
        opt_timeline = st.checkbox("â³ Timeline (DÃ²ng thá»i gian)", False)
        opt_quiz = st.checkbox("â“ Quiz & Flashcards", False)
        
        # NHÃ“M 4: Dá»® LIá»†U
        st.markdown("### 4. Dá»¯ liá»‡u & TrÃ¬nh bÃ y")
        opt_infographic = st.checkbox("ğŸ“Š Infographic Data", False)
        opt_slides = st.checkbox("ğŸ–¥ï¸ Slide Outline", False)
        opt_table = st.checkbox("ğŸ“‰ Data Table", False)

        st.divider()
        if st.button("ğŸ—‘ï¸ Reset App"):
            st.session_state.clear()
            st.rerun()

    # --- GIAO DIá»†N TAB ---
    tab1, tab2 = st.tabs(["ğŸ“‚ Upload & PhÃ¢n tÃ­ch", "ğŸ’¬ Chat Äa phÆ°Æ¡ng thá»©c"])

    # === TAB 1 ===
    with tab1:
        col_up, col_rec = st.columns(2)
        files_to_process = []
        
        with col_up:
            st.subheader("1. Upload Äa nÄƒng")
            uploaded_files = st.file_uploader("Chá»n file (Audio, PDF, Text...)", type=['mp3', 'wav', 'm4a', 'pdf', 'txt', 'md', 'csv'], accept_multiple_files=True)
        
        with col_rec:
            st.subheader("2. Ghi Ã¢m trá»±c tiáº¿p")
            audio_bytes = audio_recorder()

        if st.button("ğŸ”¥ KÃCH HOáº T PHÃ‚N TÃCH TOÃ€N DIá»†N", type="primary"):
            temp_paths = []
            if uploaded_files:
                for up_file in uploaded_files:
                    file_ext = os.path.splitext(up_file.name)[1]
                    if not file_ext: file_ext = ".txt"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
                        tmp.write(up_file.getvalue())
                        temp_paths.append(tmp.name)
            
            if audio_bytes:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_bytes)
                    temp_paths.append(tmp.name)
            
            if not temp_paths:
                st.warning("ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘áº§u vÃ o!")
            else:
                with st.spinner(f"Äang xá»­ lÃ½ {len(temp_paths)} file... (Äá»™ chi tiáº¿t: {detail_level})"):
                    try:
                        gemini_files_objs = []
                        for path in temp_paths:
                            g_file = upload_to_gemini(path)
                            gemini_files_objs.append(g_file)
                            os.remove(path)
                        
                        st.session_state.gemini_files = gemini_files_objs
                        
                        # --- XÃ‚Y Dá»°NG PROMPT Cáº¤U TRÃšC ---
                        prompt = f"""
                        Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng thá»©c. HÃ£y xá»­ lÃ½ cÃ¡c file Ä‘Æ°á»£c cung cáº¥p.
                        Äá»™ chi tiáº¿t yÃªu cáº§u: {detail_level}.
                        
                        HÃƒY TRáº¢ Lá»œI Láº¦N LÆ¯á»¢T CÃC Má»¤C SAU (Náº¿u Ä‘Æ°á»£c yÃªu cáº§u). 
                        QUAN TRá»ŒNG: Báº¯t Ä‘áº§u má»—i má»¥c báº±ng tiÃªu Ä‘á» Markdown H2 (##) chÃ­nh xÃ¡c nhÆ° bÃªn dÆ°á»›i Ä‘á»ƒ há»‡ thá»‘ng phÃ¢n tÃ¡ch.
                        """
                        
                        if opt_summary: prompt += "\n## 1. TÃ“M Táº®T & ACTION ITEMS\n- TÃ³m táº¯t Ã½ chÃ­nh.\n- Báº£ng Action Items (Ai, LÃ m gÃ¬, Deadline).\n"
                        if opt_process: prompt += "\n## 2. QUY TRÃŒNH (PROCESS)\n- TrÃ­ch xuáº¥t quy trÃ¬nh dáº¡ng Step-by-step.\n"
                        if opt_prosody: prompt += "\n## 3. Cáº¢M XÃšC & THÃI Äá»˜\n- PhÃ¢n tÃ­ch ngá»¯ Ä‘iá»‡u, tÃ¢m lÃ½ ngÆ°á»i nÃ³i.\n"
                        if opt_gossip: prompt += "\n## 4. GÃ“C BÃ€ TÃM (GOSSIP)\n- Ká»ƒ láº¡i giá»ng hÃ i hÆ°á»›c, Ä‘á»i thÆ°á»ng.\n"
                        
                        if opt_audio_script: prompt += "\n## 5. PODCAST SCRIPT\n- Ká»‹ch báº£n Ä‘á»‘i thoáº¡i Host/Guest.\n"
                        if opt_video_script: prompt += "\n## 6. VIDEO SCRIPT\n- Ká»‹ch báº£n video 2 cá»™t.\n"
                        if opt_mindmap: prompt += "\n## 7. MINDMAP CODE\n- Chá»‰ tráº£ vá» mÃ£ code Mermaid.js (graph TD) trong block ```mermaid```.\n"
                        
                        if opt_report: prompt += "\n## 8. BÃO CÃO CHUYÃŠN SÃ‚U\n- VÄƒn phong há»c thuáº­t/hÃ nh chÃ­nh.\n"
                        if opt_briefing: prompt += "\n## 9. BRIEFING DOC\n- TÃ i liá»‡u tÃ³m lÆ°á»£c nhanh.\n"
                        if opt_timeline: prompt += "\n## 10. TIMELINE Sá»° KIá»†N\n- DÃ²ng thá»i gian cÃ¡c sá»± kiá»‡n.\n"
                        if opt_quiz: prompt += "\n## 11. QUIZ & FLASHCARDS\n- CÃ¢u há»i tráº¯c nghiá»‡m vÃ  tháº» nhá»›.\n"
                        
                        if opt_infographic: prompt += "\n## 12. Dá»® LIá»†U INFOGRAPHIC\n- CÃ¡c Ä‘iá»ƒm nháº¥n sá»‘ liá»‡u.\n"
                        if opt_slides: prompt += "\n## 13. DÃ€N Ã SLIDE\n- Cáº¥u trÃºc bÃ i thuyáº¿t trÃ¬nh.\n"
                        if opt_table: prompt += "\n## 14. Báº¢NG Dá»® LIá»†U\n- Báº£ng Markdown so sÃ¡nh/thá»‘ng kÃª.\n"

                        model = genai.GenerativeModel(model_version)
                        response = model.generate_content([prompt] + gemini_files_objs)
                        
                        st.session_state.analysis_result = response.text
                        st.success("âœ… Xá»­ lÃ½ xong!")
                    except Exception as e:
                        st.error(f"Lá»—i: {e}")

        # --- HIá»‚N THá»Š Káº¾T QUáº¢ Dáº NG THáºº (EXPANDERS) ---
        if st.session_state.analysis_result:
            st.divider()
            full_text = st.session_state.analysis_result
            
            # NÃºt táº£i vá» tá»•ng há»£p
            doc = create_docx(full_text)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("ğŸ“¥ Táº£i BÃ¡o CÃ¡o Tá»•ng Há»£p (.docx)", f, "Universal_Report.docx", type="primary")
            os.remove(doc_io.name)
            
            st.markdown("### ğŸ” Káº¾T QUáº¢ CHI TIáº¾T (Báº¥m Ä‘á»ƒ má»Ÿ tá»«ng má»¥c)")
            
            # HÃ m hiá»ƒn thá»‹ thÃ´ng minh: Tá»± Ä‘á»™ng cáº¯t text theo tiÃªu Ä‘á» ##
            sections = full_text.split("## ")
            for section in sections:
                if not section.strip(): continue
                
                # Láº¥y dÃ²ng Ä‘áº§u tiÃªn lÃ m tiÃªu Ä‘á» tháº»
                lines = section.split("\n")
                title = lines[0].strip()
                content = "\n".join(lines[1:])
                
                # Xá»­ lÃ½ riÃªng cho Mindmap Ä‘á»ƒ váº½ hÃ¬nh
                if "MINDMAP" in title.upper() or "mermaid" in content:
                    with st.expander(f"ğŸ§  {title}", expanded=True):
                        try:
                            mermaid_code = content.split("```mermaid")[1].split("```")[0]
                            st_mermaid(mermaid_code, height=600) # Váº½ hÃ¬nh to hÆ¡n
                            st.code(mermaid_code, language="mermaid")
                        except:
                            st.markdown(content)
                else:
                    # CÃ¡c má»¥c khÃ¡c dÃ¹ng Expander thÆ°á»ng
                    with st.expander(f"ğŸ“Œ {title}", expanded=False):
                        st.markdown(content)

    # === TAB 2 ===
    with tab2:
        st.header("ğŸ’¬ Chat vá»›i Dá»¯ liá»‡u")
        if not st.session_state.gemini_files:
            st.info("ğŸ‘ˆ Vui lÃ²ng Upload file á»Ÿ Tab 1 trÆ°á»›c.")
        else:
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if user_input := st.chat_input("Há»i chi tiáº¿t..."):
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                with st.chat_message("user"): st.markdown(user_input)
                with st.chat_message("assistant"):
                    with st.spinner("Äang suy nghÄ©..."):
                        try:
                            chat_model = genai.GenerativeModel(model_version)
                            response = chat_model.generate_content(
                                st.session_state.gemini_files + 
                                [f"YÃªu cáº§u: Tráº£ lá»i dá»±a trÃªn file. Äá»™ chi tiáº¿t: {detail_level}. CÃ¢u há»i: {user_input}"]
                            )
                            st.markdown(response.text)
                            st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                        except Exception as e: st.error(f"Lá»—i chat: {e}")

if __name__ == "__main__":
    main()
