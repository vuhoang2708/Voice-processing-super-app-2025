import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- 1. Cáº¤U HÃŒNH TRANG (Báº®T BUá»˜C Äáº¦U TIÃŠN) ---
st.set_page_config(page_title="Universal AI Studio", page_icon="âœ…", layout="wide")

# --- 2. KHá»I Táº O SESSION STATE (AN TOÃ€N) ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""
if "is_auto_running" not in st.session_state: st.session_state.is_auto_running = False
if "loop_count" not in st.session_state: st.session_state.loop_count = 0

# --- 3. BIáº¾N TOÃ€N Cá»¤C ---
STRICT_RULES = "CHá»ˆ DÃ™NG FILE Gá»C. Cáº¤M Bá»ŠA TÃŠN DIá»„N GIáº¢. Cáº¤M Bá»ŠA Ná»˜I DUNG. TRÃCH DáºªN GIá»œ [mm:ss]."

# --- 4. HÃ€M Há»– TRá»¢ ---
def configure_genai(user_key=None):
    api_key = user_key
    if not api_key:
        # Láº¥y key tá»« Secrets má»™t cÃ¡ch an toÃ n
        try:
            if "SYSTEM_KEYS" in st.secrets:
                keys = st.secrets["SYSTEM_KEYS"]
                if isinstance(keys, str): 
                    keys = [k.strip() for k in keys.replace('[','').replace(']','').replace('"','').replace("'",'').split(',')]
                if keys: api_key = random.choice(keys)
            elif "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
        except: pass
    
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_optimized_models():
    # Danh sÃ¡ch cá»©ng Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng lá»—i logic tÃ¬m kiáº¿m
    # Æ¯u tiÃªn 3.0 Flash Preview -> 2.0 Flash -> 1.5 Flash
    return [
        "models/gemini-3.0-flash-preview", # Má»›i nháº¥t
        "models/gemini-2.0-flash-exp",
        "models/gemini-1.5-flash",         # á»”n Ä‘á»‹nh nháº¥t
        "models/gemini-1.5-pro"
    ]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('BÃO CÃO', 0)
    # LÃ m sáº¡ch cÆ¡ báº£n, khÃ´ng lá»c dÃ²ng quÃ¡ gáº¯t
    clean_content = content.replace("```markdown", "").replace("```", "")
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- 5. MAIN APP (Bá»ŒC TRY-EXCEPT Äá»‚ CHá»NG TRáº®NG TRANG) ---
def main():
    try:
        st.title("âœ… Universal AI Studio (Safe Mode)")
        
        # --- SIDEBAR ---
        with st.sidebar:
            st.header("ğŸ¯ CHáº¾ Äá»˜")
            main_mode = st.radio("Má»¥c tiÃªu:", ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn", "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u"))
            
            st.divider()
            
            if main_mode == "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u":
                st.subheader("VÅ© khÃ­:")
                c1, c2 = st.columns(2)
                with c1:
                    opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t", True)
                    opt_action = st.checkbox("âœ… HÃ nh Ä‘á»™ng", True)
                    opt_process = st.checkbox("ğŸ”„ Quy trÃ¬nh", False)
                with c2:
                    opt_prosody = st.checkbox("ğŸ­ Cáº£m xÃºc", False)
                    opt_mindmap = st.checkbox("ğŸ§  Mindmap", True)
                    opt_quiz = st.checkbox("â“ Quiz", False)
                    opt_slides = st.checkbox("ğŸ–¥ï¸ Slide", False)
            else:
                st.info("Cháº¿ Ä‘á»™ Gá»¡ bÄƒng sáº½ cháº¡y ná»‘i tiáº¿p tá»± Ä‘á»™ng.")
                auto_continue = st.checkbox("Tá»± Ä‘á»™ng ná»‘i Ä‘oáº¡n", value=True)
            
            st.divider()
            with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & Key"):
                user_key = st.text_input("Key riÃªng:", type="password")
                if configure_genai(user_key):
                    st.success("ÄÃ£ káº¿t ná»‘i!")
                    models = get_optimized_models()
                    model_version = st.selectbox("Engine:", models, index=0)
                    if main_mode.startswith("ğŸ“Š"):
                        detail_level = st.select_slider("Chi tiáº¿t:", ["SÆ¡ lÆ°á»£c", "TiÃªu chuáº©n", "SÃ¢u"], value="SÃ¢u")
                else: st.error("ChÆ°a káº¿t ná»‘i!")

            if st.button("ğŸ—‘ï¸ Reset"):
                st.session_state.clear(); st.rerun()

        # --- TABS ---
        tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½", "ğŸ’¬ Chat"])

        with tab_work:
            if not st.session_state.is_auto_running:
                up_files = st.file_uploader("Upload file", accept_multiple_files=True)
                audio_bytes = audio_recorder()

                if st.button("ğŸš€ Báº®T Äáº¦U", type="primary"):
                    temp_paths = []
                    if up_files:
                        for f in up_files:
                            ext = os.path.splitext(f.name)[1] or ".txt"
                            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                                tmp.write(f.getvalue()); temp_paths.append(tmp.name)
                    if audio_bytes:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                            tmp.write(audio_bytes); temp_paths.append(tmp.name)
                    
                    if not temp_paths:
                        st.warning("ChÆ°a cÃ³ file!")
                    else:
                        with st.spinner(f"Äang xá»­ lÃ½ vá»›i {model_version}..."):
                            try:
                                g_files = [upload_to_gemini(p) for p in temp_paths]
                                st.session_state.gemini_files = g_files
                                
                                # Cáº¥u hÃ¬nh an toÃ n
                                gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2)

                                if main_mode.startswith("ğŸ“"):
                                    prompt = f"""
                                    {STRICT_RULES}
                                    NHIá»†M Vá»¤: Gá»¡ bÄƒng NGUYÃŠN VÄ‚N 100%.
                                    YÃŠU Cáº¦U:
                                    1. Báº¯t Ä‘áº§u má»—i cÃ¢u báº±ng [PhÃºt:GiÃ¢y].
                                    2. Viáº¿t láº¡i chÃ­nh xÃ¡c tá»«ng tá»«.
                                    3. Äá»‹nh danh: 'Diá»…n giáº£'.
                                    4. NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t.
                                    """
                                    if auto_continue:
                                        st.session_state.is_auto_running = True
                                        st.session_state.loop_count = 1
                                else:
                                    prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch sÃ¢u {detail_level}:\n"
                                    if opt_summary: prompt += "## TÃ“M Táº®T\n"
                                    if opt_action: prompt += "## HÃ€NH Äá»˜NG\n"
                                    if opt_process: prompt += "## QUY TRÃŒNH\n"
                                    if opt_prosody: prompt += "## Cáº¢M XÃšC\n"
                                    if opt_mindmap: prompt += "## MÃƒ SÆ  Äá»’ (Mermaid)\n"
                                    if opt_quiz: prompt += "## QUIZ\n"
                                    if opt_slides: prompt += "## SLIDE\n"

                                # FALLBACK THá»¦ CÃ”NG (ÄÆ¡n giáº£n hÃ³a Ä‘á»ƒ trÃ¡nh lá»—i)
                                try:
                                    model = genai.GenerativeModel(model_version)
                                    response = model.generate_content([prompt] + g_files, generation_config=gen_config)
                                except Exception as e:
                                    if "429" in str(e) or "404" in str(e):
                                        st.warning(f"Model {model_version} lá»—i, chuyá»ƒn sang 1.5 Flash...")
                                        model = genai.GenerativeModel("models/gemini-1.5-flash")
                                        response = model.generate_content([prompt] + g_files, generation_config=gen_config)
                                    else: raise e

                                st.session_state.analysis_result = response.text
                                st.rerun()
                            except Exception as e: st.error(f"Lá»—i xá»­ lÃ½: {e}")

            # HIá»‚N THá»Š Káº¾T QUáº¢
            if st.session_state.analysis_result:
                if st.session_state.is_auto_running:
                    st.warning(f"ğŸ”„ Äang tá»± Ä‘á»™ng cháº¡y tiáº¿p (VÃ²ng {st.session_state.loop_count})...")
                    if st.button("ğŸ›‘ Dá»ªNG"):
                        st.session_state.is_auto_running = False
                        st.success("ÄÃ£ dá»«ng."); st.rerun()

                st.divider()
                res = st.session_state.analysis_result
                
                # Hiá»ƒn thá»‹ Mindmap
                if "```mermaid" in res:
                    try:
                        m_code = res.split("```mermaid")[1].split("```")[0]
                        st_mermaid(m_code, height=500)
                    except: pass
                
                # Hiá»ƒn thá»‹ Text (DÃ¹ng Expander Ä‘Æ¡n giáº£n)
                sections = res.split("## ")
                for s in sections:
                    if not s.strip(): continue
                    lines = s.split("\n")
                    with st.expander(f"ğŸ“Œ {lines[0].strip()}", expanded=True):
                        st.markdown("\n".join(lines[1:]))

                # Download
                doc = create_docx(res)
                doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
                doc.save(doc_io.name)
                with open(doc_io.name, "rb") as f:
                    st.download_button("ğŸ“¥ Táº£i BÃ¡o CÃ¡o", f, "Bao_Cao.docx", type="primary")
                os.remove(doc_io.name)

                # AUTO-CONTINUE
                if st.session_state.is_auto_running and main_mode.startswith("ğŸ“"):
                    st.divider()
                    placeholder = st.empty()
                    for i in range(3, 0, -1):
                        placeholder.info(f"â³ Cháº¡y tiáº¿p trong {i}s...")
                        time.sleep(1)
                    placeholder.empty()
                    
                    with st.spinner("Äang nghe tiáº¿p..."):
                        try:
                            cont_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2)
                            model = genai.GenerativeModel(model_version) # DÃ¹ng láº¡i model Ä‘ang chá»n
                            last_part = res[-500:]
                            c_prompt = f"""
                            CONTEXT: Äang gá»¡ bÄƒng dá»Ÿ dang.
                            Má» NEO: "...{last_part}"
                            NHIá»†M Vá»¤: TÃ¬m má» neo, viáº¿t tiáº¿p NGUYÃŠN VÄ‚N Ä‘oáº¡n sau. KHÃ”NG viáº¿t láº¡i má» neo.
                            """
                            
                            # Fallback cho Ä‘oáº¡n ná»‘i tiáº¿p
                            try:
                                c_res = model.generate_content([c_prompt] + st.session_state.gemini_files, generation_config=cont_config)
                            except:
                                model = genai.GenerativeModel("models/gemini-1.5-flash")
                                c_res = model.generate_content([c_prompt] + st.session_state.gemini_files, generation_config=cont_config)

                            if len(c_res.text) < 50 or "káº¿t thÃºc" in c_res.text.lower():
                                st.session_state.is_auto_running = False
                                st.success("âœ… ÄÃ£ xong!")
                            else:
                                st.session_state.analysis_result += "\n\n" + c_res.text
                                st.session_state.loop_count += 1
                                st.rerun()
                        except Exception as e:
                            st.error(f"Lá»—i: {e}")
                            st.session_state.is_auto_running = False

        with tab_chat:
            st.header("ğŸ’¬ Chat")
            if st.session_state.gemini_files:
                for m in st.session_state.chat_history:
                    with st.chat_message(m["role"]): st.markdown(m["content"])
                if inp := st.chat_input("Há»i AI..."):
                    st.session_state.chat_history.append({"role": "user", "content": inp})
                    with st.chat_message("user"): st.markdown(inp)
                    with st.chat_message("assistant"):
                        try:
                            m = genai.GenerativeModel(model_version)
                            r = m.generate_content(st.session_state.gemini_files + [f"Tráº£ lá»i: {inp}"])
                            st.markdown(r.text); st.session_state.chat_history.append({"role": "assistant", "content": r.text})
                        except: st.error("Lá»—i chat.")
            else: st.info("ğŸ‘ˆ Upload file trÆ°á»›c.")

    except Exception as e:
        st.error(f"ğŸ”¥ Lá»–I NGHIÃŠM TRá»ŒNG (CRASH): {e}")
        st.stop()

if __name__ == "__main__":
    main()
