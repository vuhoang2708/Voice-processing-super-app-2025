import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio (Time-Sync)", page_icon="â±ï¸", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: #1e3c72; color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; background-color: #ffffff;}
    .stMarkdown h2 {color: #1a2a6c; border-bottom: 2px solid #eee; padding-bottom: 5px;}
    div[data-testid="stButton"] > button:contains("Dá»ªNG") {background-color: #d32f2f !important;}
</style>
""", unsafe_allow_html=True)

# --- 2. BIáº¾N TOÃ€N Cá»¤C ---
STRICT_RULES = "CHá»ˆ DÃ™NG FILE Gá»C. Cáº¤M Bá»ŠA TÃŠN DIá»„N GIáº¢. Cáº¤M Bá»ŠA Ná»˜I DUNG. Báº®T BUá»˜C GHI Má»C THá»œI GIAN [mm:ss] á» Äáº¦U Má»–I ÄOáº N."

# --- 3. QUáº¢N LÃ SESSION ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""
if "is_auto_running" not in st.session_state: st.session_state.is_auto_running = False
if "loop_count" not in st.session_state: st.session_state.loop_count = 0

# --- 4. HÃ€M Há»– TRá»¢ ---
def configure_genai(user_key=None):
    api_key = user_key
    if not api_key:
        try:
            if "SYSTEM_KEYS" in st.secrets:
                keys = st.secrets["SYSTEM_KEYS"]
                if isinstance(keys, str): 
                    keys = [k.strip() for k in keys.replace('[','').replace(']','').replace('"','').replace("'",'').split(',')]
                if keys: api_key = random.choice(keys)
            elif "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
        except: pass
    
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_optimized_models():
    # Danh sÃ¡ch cá»©ng Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n
    return ["models/gemini-1.5-flash", "models/gemini-1.5-pro", "models/gemini-2.0-flash-exp"]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('BÃO CÃO', 0)
    clean_content = content.replace("```markdown", "").replace("```", "")
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

def get_safe_response(response):
    try:
        finish_reason = response.candidates[0].finish_reason
        if finish_reason in [1, 2]: return response.text
        elif finish_reason == 3: return "\n\n[Cáº¢NH BÃO: Ná»™i dung bá»‹ cháº·n do Safety.]"
        elif finish_reason == 4: return "\n\n[Dá»ªNG: PhÃ¡t hiá»‡n ná»™i dung cÃ³ báº£n quyá»n.]"
        else: return f"\n\n[Lá»—i: Finish Reason {finish_reason}]"
    except: return response.text

def get_last_timestamp(text):
    """TÃ¬m má»‘c thá»i gian cuá»‘i cÃ¹ng trong vÄƒn báº£n dáº¡ng [mm:ss]"""
    matches = re.findall(r'\[(\d{1,2}:\d{2})\]', text)
    if matches:
        return matches[-1]
    return None

# --- 5. MAIN APP ---
def main():
    st.title("â±ï¸ Universal AI Studio (Time-Sync Fix)")
    
    with st.sidebar:
        st.header("ğŸ¯ CHáº¾ Äá»˜")
        main_mode = st.radio("Má»¥c tiÃªu:", ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn", "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u"))
        
        if main_mode == "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u":
            st.subheader("VÅ© khÃ­:")
            c1, c2 = st.columns(2)
            with c1:
                opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t", True)
                opt_action = st.checkbox("âœ… HÃ nh Ä‘á»™ng", True)
                opt_process = st.checkbox("ğŸ”„ Quy trÃ¬nh", False)
            with c2:
                opt_prosody = st.checkbox("ğŸ­ Cáº£m xÃºc", False)
                opt_mindmap = st.checkbox("ğŸ§  Mindmap", True)
                opt_quiz = st.checkbox("â“ Quiz", False)
        else:
            st.info("Cháº¿ Ä‘á»™ Gá»¡ bÄƒng sáº½ cháº¡y ná»‘i tiáº¿p tá»± Ä‘á»™ng.")
            auto_continue = st.checkbox("Tá»± Ä‘á»™ng ná»‘i Ä‘oáº¡n", value=True)
        
        st.divider()
        with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & Key"):
            user_key = st.text_input("Key riÃªng:", type="password")
            if configure_genai(user_key):
                st.success("ÄÃ£ káº¿t ná»‘i!")
                models = get_optimized_models()
                model_version = st.selectbox("Engine:", models, index=0)
            else: st.error("ChÆ°a káº¿t ná»‘i!")

        if st.button("ğŸ—‘ï¸ Reset"):
            st.session_state.clear(); st.rerun()

    # --- TABS ---
    tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½", "ğŸ’¬ Chat"])

    with tab_work:
        if not st.session_state.is_auto_running:
            up_files = st.file_uploader("Upload file", accept_multiple_files=True)
            audio_bytes = audio_recorder()

            if st.button("ğŸš€ Báº®T Äáº¦U", type="primary"):
                temp_paths = []
                if up_files:
                    for f in up_files:
                        ext = os.path.splitext(f.name)[1] or ".txt"
                        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                            tmp.write(f.getvalue()); temp_paths.append(tmp.name)
                if audio_bytes:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(audio_bytes); temp_paths.append(tmp.name)
                
                if not temp_paths:
                    st.warning("ChÆ°a cÃ³ file!")
                else:
                    with st.spinner(f"Äang xá»­ lÃ½ vá»›i {model_version}..."):
                        try:
                            g_files = [upload_to_gemini(p) for p in temp_paths]
                            st.session_state.gemini_files = g_files
                            
                            # Táº¯t bá»™ lá»c an toÃ n
                            safety_settings = [
                                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                            ]
                            
                            gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2)

                            if main_mode.startswith("ğŸ“"):
                                prompt = f"""
                                {STRICT_RULES}
                                NHIá»†M Vá»¤: Gá»¡ bÄƒng NGUYÃŠN VÄ‚N 100%.
                                YÃŠU Cáº¦U:
                                1. Báº¯t Ä‘áº§u má»—i cÃ¢u báº±ng [PhÃºt:GiÃ¢y]. VÃ­ dá»¥: [00:15] Xin chÃ o...
                                2. Viáº¿t láº¡i chÃ­nh xÃ¡c tá»«ng tá»«.
                                3. Äá»‹nh danh: 'Diá»…n giáº£'.
                                4. NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t.
                                """
                                if auto_continue:
                                    st.session_state.is_auto_running = True
                                    st.session_state.loop_count = 1
                            else:
                                prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch sÃ¢u:\n## TÃ“M Táº®T\n## HÃ€NH Äá»˜NG\n## QUY TRÃŒNH\n## Cáº¢M XÃšC\n## MÃƒ SÆ  Äá»’ (Mermaid)\n## QUIZ"

                            model = genai.GenerativeModel(model_version)
                            response = model.generate_content(
                                [prompt] + g_files, 
                                generation_config=gen_config,
                                safety_settings=safety_settings
                            )
                            
                            safe_text = get_safe_response(response)
                            st.session_state.analysis_result = safe_text
                            st.rerun()
                        except Exception as e: st.error(f"Lá»—i xá»­ lÃ½: {e}")

        # HIá»‚N THá»Š Káº¾T QUáº¢
        if st.session_state.analysis_result:
            if st.session_state.is_auto_running:
                st.warning(f"ğŸ”„ Äang tá»± Ä‘á»™ng cháº¡y tiáº¿p (VÃ²ng {st.session_state.loop_count})...")
                if st.button("ğŸ›‘ Dá»ªNG"):
                    st.session_state.is_auto_running = False
                    st.success("ÄÃ£ dá»«ng."); st.rerun()

            st.divider()
            res = st.session_state.analysis_result
            
            if "```mermaid" in res:
                try:
                    m_code = res.split("```mermaid")[1].split("```")[0]
                    st_mermaid(m_code, height=500)
                except: pass
            
            sections = res.split("## ")
            for s in sections:
                if not s.strip(): continue
                lines = s.split("\n")
                with st.expander(f"ğŸ“Œ {lines[0].strip()}", expanded=True):
                    st.markdown("\n".join(lines[1:]))

            doc = create_docx(res)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("ğŸ“¥ Táº£i BÃ¡o CÃ¡o", f, "Bao_Cao.docx", type="primary")
            os.remove(doc_io.name)

            # AUTO-CONTINUE
            if st.session_state.is_auto_running and main_mode.startswith("ğŸ“"):
                if "[Dá»ªNG:" in res or "[Cáº¢NH BÃO:" in res:
                    st.session_state.is_auto_running = False
                    st.error("âš ï¸ Dá»«ng do báº£n quyá»n/an toÃ n.")
                else:
                    st.divider()
                    placeholder = st.empty()
                    for i in range(3, 0, -1):
                        placeholder.info(f"â³ Cháº¡y tiáº¿p trong {i}s...")
                        time.sleep(1)
                    placeholder.empty()
                    
                    with st.spinner("Äang nghe tiáº¿p..."):
                        try:
                            cont_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2)
                            model = genai.GenerativeModel(model_version)
                            
                            # --- LOGIC Má»šI: TÃŒM Má»C THá»œI GIAN CUá»I CÃ™NG ---
                            last_timestamp = get_last_timestamp(res)
                            last_part = res[-300:]
                            
                            if last_timestamp:
                                time_instruction = f"Báº®T Äáº¦U NGHE Tá»ª PHÃšT {last_timestamp} TRá» ÄI."
                            else:
                                time_instruction = "Tiáº¿p tá»¥c ngay sau Ä‘oáº¡n vÄƒn báº£n cuá»‘i cÃ¹ng."

                            c_prompt = f"""
                            CONTEXT: Äang gá»¡ bÄƒng dá»Ÿ dang.
                            Má»C THá»œI GIAN CUá»I CÃ™NG ÄÃƒ GHI: {last_timestamp}
                            ÄOáº N CUá»I VÄ‚N Báº¢N: "...{last_part}"
                            
                            NHIá»†M Vá»¤ Cáº¤P BÃCH:
                            1. {time_instruction}
                            2. Viáº¿t tiáº¿p NGUYÃŠN VÄ‚N Ä‘oáº¡n sau.
                            3. TUYá»†T Äá»I KHÃ”NG quay láº¡i tá»« Ä‘áº§u (00:00).
                            4. TUYá»†T Äá»I KHÃ”NG viáº¿t láº¡i Ä‘oáº¡n cÅ©.
                            5. Tiáº¿p tá»¥c ghi má»‘c thá»i gian [mm:ss].
                            """
                            
                            safety_settings = [
                                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                            ]

                            c_res = model.generate_content(
                                [c_prompt] + st.session_state.gemini_files, 
                                generation_config=cont_config,
                                safety_settings=safety_settings
                            )
                            
                            safe_c_text = get_safe_response(c_res)

                            if len(safe_c_text) < 50 or "káº¿t thÃºc" in safe_c_text.lower() or "[Dá»ªNG:" in safe_c_text:
                                st.session_state.is_auto_running = False
                                st.success("âœ… ÄÃ£ xong!")
                                if "[Dá»ªNG:" in safe_c_text:
                                    st.session_state.analysis_result += "\n\n" + safe_c_text
                                    st.rerun()
                            else:
                                st.session_state.analysis_result += "\n\n" + safe_c_text
                                st.session_state.loop_count += 1
                                st.rerun()
                        except Exception as e:
                            st.error(f"Lá»—i: {e}")
                            st.session_state.is_auto_running = False

    with tab_chat:
        st.header("ğŸ’¬ Chat")
        if st.session_state.gemini_files:
            for m in st.session_state.chat_history:
                with st.chat_message(m["role"]): st.markdown(m["content"])
            if inp := st.chat_input("Há»i AI..."):
                st.session_state.chat_history.append({"role": "user", "content": inp})
                with st.chat_message("user"): st.markdown(inp)
                with st.chat_message("assistant"):
                    try:
                        m = genai.GenerativeModel(model_version)
                        r = m.generate_content(
                            st.session_state.gemini_files + [f"Tráº£ lá»i: {inp}"],
                            safety_settings=SAFETY_SETTINGS
                        )
                        st.markdown(r.text); st.session_state.chat_history.append({"role": "assistant", "content": r.text})
                    except: st.error("Lá»—i chat.")
        else: st.info("ğŸ‘ˆ Upload file trÆ°á»›c.")

if __name__ == "__main__":
    main()
