import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio", page_icon="ğŸ™ï¸", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: #1e3c72; color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; background-color: #ffffff;}
    .stMarkdown h2 {color: #1a2a6c; border-bottom: 2px solid #eee; padding-bottom: 5px;}
    div[data-testid="stButton"] > button:contains("Dá»ªNG") {background-color: #d32f2f !important;}
</style>
""", unsafe_allow_html=True)

# --- 2. BIáº¾N TOÃ€N Cá»¤C & SESSION ---
STRICT_RULES = "CHá»ˆ DÃ™NG FILE Gá»C. Cáº¤M Bá»ŠA TÃŠN DIá»„N GIáº¢. Cáº¤M Bá»ŠA Ná»˜I DUNG. TRÃCH DáºªN GIá»œ [mm:ss]."

if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""
if "is_auto_running" not in st.session_state: st.session_state.is_auto_running = False
if "loop_count" not in st.session_state: st.session_state.loop_count = 0

# --- 3. CÃC HÃ€M Há»– TRá»¢ (HELPER FUNCTIONS) ---
def configure_genai(user_key=None):
    api_key = None
    if user_key:
        api_key = user_key
    else:
        try:
            if "SYSTEM_KEYS" in st.secrets:
                keys = st.secrets["SYSTEM_KEYS"]
                if isinstance(keys, str): 
                    keys = [k.strip() for k in keys.replace('[','').replace(']','').replace('"','').replace("'",'').split(',')]
                api_key = random.choice(keys)
            elif "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
        except: pass
    
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_optimized_models():
    try:
        models = genai.list_models()
        valid = [m.name for m in models if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name]
        # Æ¯u tiÃªn Flash 3.0 Preview
        priority = ["gemini-3-flash-preview", "gemini-2.0-flash-exp", "gemini-1.5-flash"]
        final_list = []
        for p in priority:
            found = [m for m in valid if p in m]
            for f in found:
                if f not in final_list: final_list.append(f)
        for v in valid:
            if v not in final_list: final_list.append(v)
        return final_list if final_list else ["models/gemini-1.5-flash"]
    except: return ["models/gemini-1.5-flash"]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('BÃO CÃO PHÃ‚N TÃCH AI', 0)
    clean_content = re.sub(r'<[^>]+>', '', content)
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- 4. GIAO DIá»†N CHÃNH (MAIN APP) ---
def main():
    st.title("ğŸš€ Universal AI Studio (Final Tuned)")
    
    # --- SIDEBAR ---
    with st.sidebar:
        st.header("ğŸ¯ CHáº¾ Äá»˜ HOáº T Äá»˜NG")
        main_mode = st.radio("Má»¥c tiÃªu chÃ­nh:", ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn (Verbatim)", "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u"))
        
        st.divider()
        
        if main_mode == "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u":
            st.subheader("CHá»ŒN VÅ¨ KHÃ:")
            opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t ná»™i dung", True)
            opt_action = st.checkbox("âœ… Danh sÃ¡ch HÃ nh Ä‘á»™ng", True)
            opt_process = st.checkbox("ğŸ”„ TrÃ­ch xuáº¥t Quy trÃ¬nh", False)
            opt_prosody = st.checkbox("ğŸ­ PhÃ¢n tÃ­ch Cáº£m xÃºc", False)
            opt_mindmap = st.checkbox("ğŸ§  Váº½ SÆ¡ Ä‘á»“ tÆ° duy", True)
            opt_quiz = st.checkbox("â“ CÃ¢u há»i Tráº¯c nghiá»‡m", False)
            opt_slides = st.checkbox("ğŸ–¥ï¸ DÃ n Ã½ Slide", False)
        else:
            st.info("ğŸ’¡ Cháº¿ Ä‘á»™ Gá»¡ bÄƒng sáº½ chÃ©p láº¡i tá»«ng tá»« má»™t. Náº¿u file dÃ i, há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng cháº¡y ná»‘i tiáº¿p nhiá»u láº§n.")
            auto_continue = st.checkbox("Tá»± Ä‘á»™ng ná»‘i Ä‘oáº¡n (Auto-Continue)", value=True)
        
        st.divider()
        with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & Key"):
            user_key = st.text_input("Nháº­p Key riÃªng:", type="password")
            if configure_genai(user_key):
                st.success("ÄÃ£ káº¿t ná»‘i!")
                models = get_optimized_models()
                model_version = st.selectbox("Engine:", models, index=0)
                if main_mode.startswith("ğŸ“Š"):
                    detail_level = st.select_slider("Äá»™ chi tiáº¿t:", ["SÆ¡ lÆ°á»£c", "TiÃªu chuáº©n", "SÃ¢u"], value="SÃ¢u")
            else: st.error("ChÆ°a káº¿t ná»‘i!")

        if st.button("ğŸ—‘ï¸ Reset App"):
            st.session_state.clear(); st.rerun()

    # --- TABS ---
    tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½ Dá»¯ liá»‡u", "ğŸ’¬ Chat"])

    with tab_work:
        if not st.session_state.is_auto_running:
            up_files = st.file_uploader("Upload file", accept_multiple_files=True)
            audio_bytes = audio_recorder()

            if st.button("ğŸš€ Báº®T Äáº¦U THá»°C THI", type="primary"):
                temp_paths = []
                if up_files:
                    for f in up_files:
                        ext = os.path.splitext(f.name)[1] or ".txt"
                        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                            tmp.write(f.getvalue()); temp_paths.append(tmp.name)
                if audio_bytes:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(audio_bytes); temp_paths.append(tmp.name)
                
                if not temp_paths:
                    st.warning("ChÆ°a cÃ³ file!")
                else:
                    with st.spinner(f"Äang khá»Ÿi Ä‘á»™ng {model_version}..."):
                        try:
                            g_files = [upload_to_gemini(p) for p in temp_paths]
                            st.session_state.gemini_files = g_files
                            
                            if main_mode.startswith("ğŸ“"):
                                # Cáº¤U HÃŒNH VÃ€NG: TEMP 0.2 Äá»‚ TRÃNH Láº¶P, TOP_P 0.95 Äá»‚ CHÃNH XÃC
                                gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2, top_p=0.95)
                                prompt = """
                                Báº N LÃ€ Má»˜T MÃY Gá»  BÄ‚NG CHUYÃŠN NGHIá»†P.
                                NHIá»†M Vá»¤: Nghe vÃ  chÃ©p láº¡i NGUYÃŠN VÄ‚N (Verbatim) tá»«ng tá»« má»™t trong file Ã¢m thanh.
                                
                                QUY Táº®C Báº®T BUá»˜C:
                                1. KHÃ”NG ÄÆ¯á»¢C TÃ“M Táº®T. KHÃ”NG ÄÆ¯á»¢C LÆ¯á»¢C Bá».
                                2. Viáº¿t láº¡i chÃ­nh xÃ¡c nhá»¯ng gÃ¬ nghe tháº¥y.
                                3. Náº¾U Gáº¶P ÄOáº N Láº¶P Láº I HOáº¶C NHIá»„U: HÃ£y bá» qua, khÃ´ng Ä‘Æ°á»£c viáº¿t láº·p tá»« vÃ´ nghÄ©a.
                                4. Äá»‹nh dáº¡ng: [PhÃºt:GiÃ¢y] Ná»™i dung...
                                5. Náº¿u file quÃ¡ dÃ i, hÃ£y viáº¿t Ä‘áº¿n khi háº¿t giá»›i háº¡n token thÃ¬ dá»«ng láº¡i.
                                6. NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t.
                                
                                TiÃªu Ä‘á» báº¯t Ä‘áº§u: ## Báº¢N Gá»  BÄ‚NG CHI TIáº¾T (PHáº¦N 1)
                                """
                                if auto_continue:
                                    st.session_state.is_auto_running = True
                                    st.session_state.loop_count = 1
                            else:
                                # Cáº¤U HÃŒNH CHO PHÃ‚N TÃCH: TEMP 0.4 Äá»‚ SÃNG Táº O HÆ N
                                gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.4)
                                prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch sÃ¢u {detail_level} cho cÃ¡c má»¥c:\n"
                                if opt_summary: prompt += "## 1. TÃ“M Táº®T CHI TIáº¾T\n"
                                if opt_action: prompt += "## 2. HÃ€NH Äá»˜NG Cáº¦N LÃ€M\n"
                                if opt_process: prompt += "## 3. QUY TRÃŒNH CHI TIáº¾T\n"
                                if opt_prosody: prompt += "## 4. PHÃ‚N TÃCH Cáº¢M XÃšC\n"
                                if opt_mindmap: prompt += "## 5. MÃƒ SÆ  Äá»’ TÆ¯ DUY (Mermaid)\n"
                                if opt_quiz: prompt += "## 6. CÃ‚U Há»I TRáº®C NGHIá»†M\n"
                                if opt_slides: prompt += "## 7. DÃ€N Ã SLIDE\n"

                            model = genai.GenerativeModel(model_version)
                            response = model.generate_content([prompt] + g_files, generation_config=gen_config)
                            st.session_state.analysis_result = response.text
                            st.rerun()
                        except Exception as e: st.error(f"Lá»—i: {e}")

        # --- HIá»‚N THá»Š Káº¾T QUáº¢ & LOGIC Tá»° Äá»˜NG ---
        if st.session_state.analysis_result:
            if st.session_state.is_auto_running:
                st.warning(f"ğŸ”„ Äang tá»± Ä‘á»™ng gá»¡ bÄƒng Ä‘oáº¡n tiáº¿p theo (VÃ²ng láº·p #{st.session_state.loop_count})...")
                if st.button("ğŸ›‘ Dá»ªNG Láº I NGAY"):
                    st.session_state.is_auto_running = False
                    st.success("ÄÃ£ dá»«ng.")
                    st.rerun()

            st.divider()
            res = st.session_state.analysis_result
            
            # Hiá»ƒn thá»‹
            sections = res.split("## ")
            for s in sections:
                if not s.strip(): continue
                lines = s.split("\n")
                with st.expander(f"ğŸ“Œ {lines[0].strip()}", expanded=True):
                    st.markdown("\n".join(lines[1:]))
            
            # Download
            doc = create_docx(res)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("ğŸ“¥ Táº£i BÃ¡o CÃ¡o (.docx)", f, "Bao_Cao_AI.docx", type="primary")
            os.remove(doc_io.name)

            # --- LOGIC AUTO-CONTINUE (Gá»  BÄ‚NG) ---
            if st.session_state.is_auto_running and main_mode.startswith("ğŸ“"):
                st.divider()
                placeholder = st.empty()
                for i in range(3, 0, -1):
                    placeholder.info(f"â³ Chuáº©n bá»‹ ná»‘i Ä‘oáº¡n tiáº¿p theo trong {i} giÃ¢y...")
                    time.sleep(1)
                placeholder.empty()
                
                with st.spinner(f"ğŸ¤– AI Ä‘ang nghe tiáº¿p Ä‘oáº¡n {st.session_state.loop_count + 1}..."):
                    try:
                        # Cáº¥u hÃ¬nh Temp 0.2 cho gá»¡ bÄƒng ná»‘i tiáº¿p
                        cont_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2, top_p=0.95)
                        model = genai.GenerativeModel(model_version)
                        last_part = res[-500:] 
                        
                        c_prompt = f"""
                        CONTEXT: Báº¡n Ä‘ang gá»¡ bÄƒng dá»Ÿ dang file Ã¢m thanh nÃ y.
                        Má» NEO (Äoáº¡n cuá»‘i cÃ¹ng báº¡n vá»«a viáº¿t): "...{last_part}"
                        
                        NHIá»†M Vá»¤ Cáº¤P BÃCH:
                        1. TÃ¬m vá»‹ trÃ­ cá»§a Má» NEO trong file Ã¢m thanh.
                        2. Viáº¿t tiáº¿p NGUYÃŠN VÄ‚N (Verbatim) ná»™i dung ngay sau Má» neo.
                        3. TUYá»†T Äá»I KHÃ”NG viáº¿t láº¡i Má» neo.
                        4. TUYá»†T Äá»I KHÃ”NG tÃ³m táº¯t. Viáº¿t cÃ ng chi tiáº¿t cÃ ng tá»‘t.
                        5. Náº¿u gáº·p Ä‘oáº¡n láº·p láº¡i, hÃ£y bá» qua.
                        6. Náº¿u háº¿t file thÃ¬ dá»«ng láº¡i.
                        """
                        
                        c_res = model.generate_content([c_prompt] + st.session_state.gemini_files, generation_config=cont_config)
                        
                        if len(c_res.text) < 50 or "káº¿t thÃºc" in c_res.text.lower():
                            st.session_state.is_auto_running = False
                            st.success("âœ… ÄÃ£ gá»¡ bÄƒng xong toÃ n bá»™ file!")
                        else:
                            st.session_state.analysis_result += "\n\n" + c_res.text
                            st.session_state.loop_count += 1
                            st.rerun()
                            
                    except Exception as e:
                        st.error(f"Lá»—i hoáº·c Ä‘Ã£ háº¿t file: {e}")
                        st.session_state.is_auto_running = False

    with tab_chat:
        st.header("ğŸ’¬ Chat")
        if st.session_state.gemini_files:
            for m in st.session_state.chat_history:
                with st.chat_message(m["role"]): st.markdown(m["content"])
            if inp := st.chat_input("Há»i AI..."):
                st.session_state.chat_history.append({"role": "user", "content": inp})
                with st.chat_message("user"): st.markdown(inp)
                with st.chat_message("assistant"):
                    m_chat = genai.GenerativeModel(model_version)
                    r = m_chat.generate_content(st.session_state.gemini_files + [f"Tráº£ lá»i tá»« file: {inp}"])
                    st.markdown(r.text); st.session_state.chat_history.append({"role": "assistant", "content": r.text})
        else: st.info("ğŸ‘ˆ Upload file trÆ°á»›c.")

if __name__ == "__main__":
    main()
