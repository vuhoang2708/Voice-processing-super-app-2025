import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio (Smart Retry)", page_icon="ğŸ›¡ï¸", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: #1e3c72; color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; background-color: #ffffff;}
    .stMarkdown h2 {color: #1a2a6c; border-bottom: 2px solid #eee; padding-bottom: 5px;}
    /* Style cho thÃ´ng bÃ¡o lá»—i */
    .error-box {padding: 15px; background-color: #ffebee; border: 1px solid #ffcdd2; border-radius: 5px; color: #c62828; margin-bottom: 10px;}
</style>
""", unsafe_allow_html=True)

# --- BIáº¾N TOÃ€N Cá»¤C ---
STRICT_RULES = "CHá»ˆ DÃ™NG FILE Gá»C. Cáº¤M Bá»ŠA TÃŠN DIá»„N GIáº¢. Cáº¤M Bá»ŠA Ná»˜I DUNG. TRÃCH DáºªN GIá»œ [mm:ss]."

# --- QUáº¢N LÃ SESSION ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""
# Biáº¿n kiá»ƒm soÃ¡t tráº¡ng thÃ¡i lá»—i Quota
if "quota_error_state" not in st.session_state: st.session_state.quota_error_state = False
if "current_prompt" not in st.session_state: st.session_state.current_prompt = ""
if "current_config" not in st.session_state: st.session_state.current_config = None

# --- HÃ€M Há»– TRá»¢ ---
def get_system_key():
    """Láº¥y key tá»« Secrets"""
    try:
        if "SYSTEM_KEYS" in st.secrets:
            keys = st.secrets["SYSTEM_KEYS"]
            if isinstance(keys, str): 
                keys = [k.strip() for k in keys.replace('[','').replace(']','').replace('"','').replace("'",'').split(',')]
            return random.choice(keys)
        elif "GOOGLE_API_KEY" in st.secrets:
            return st.secrets["GOOGLE_API_KEY"]
    except: return None
    return None

def configure_genai(specific_key=None):
    # Náº¿u cÃ³ key cá»¥ thá»ƒ (do ngÆ°á»i dÃ¹ng nháº­p lÃºc lá»—i) thÃ¬ dÃ¹ng luÃ´n
    api_key = specific_key if specific_key else get_system_key()
    
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_optimized_models():
    try:
        models = genai.list_models()
        valid = [m.name for m in models if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name]
        # Æ¯u tiÃªn 3.0 Flash Preview
        priority = ["gemini-3-flash-preview", "gemini-2.0-flash-exp", "gemini-1.5-flash"]
        final_list = []
        for p in priority:
            found = [m for m in valid if p in m]
            for f in found:
                if f not in final_list: final_list.append(f)
        for v in valid:
            if v not in final_list: final_list.append(v)
        return final_list if final_list else ["models/gemini-1.5-flash"]
    except: return ["models/gemini-1.5-flash"]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('BÃO CÃO PHÃ‚N TÃCH AI', 0)
    clean_content = re.sub(r'<[^>]+>', '', content)
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- MAIN APP ---
def main():
    st.title("ğŸ›¡ï¸ Universal AI Studio (Smart Retry)")
    
    # --- SIDEBAR ---
    with st.sidebar:
        st.header("ğŸ› ï¸ KHO VÅ¨ KHÃ")
        main_mode = st.radio("Má»¥c tiÃªu chÃ­nh:", ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn", "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u"))
        
        if main_mode == "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u":
            c1, c2 = st.columns(2)
            with c1:
                opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t", True)
                opt_action = st.checkbox("âœ… HÃ nh Ä‘á»™ng", True)
                opt_process = st.checkbox("ğŸ”„ Quy trÃ¬nh", False)
            with c2:
                opt_prosody = st.checkbox("ğŸ­ Cáº£m xÃºc", False)
                opt_mindmap = st.checkbox("ğŸ§  Mindmap", True)
                opt_quiz = st.checkbox("â“ Quiz/Slide", False)
        
        st.divider()
        with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & Key"):
            # Chá»‰ dÃ¹ng Ä‘á»ƒ nháº­p key ban Ä‘áº§u, khÃ´ng dÃ¹ng cho xá»­ lÃ½ lá»—i
            initial_key = st.text_input("Key cÃ¡ nhÃ¢n (TÃ¹y chá»n):", type="password")
            if configure_genai(initial_key):
                st.success("ÄÃ£ káº¿t ná»‘i!")
                models = get_optimized_models()
                model_version = st.selectbox("Engine:", models, index=0)
                detail_level = st.select_slider("Äá»™ chi tiáº¿t:", options=["SÆ¡ lÆ°á»£c", "TiÃªu chuáº©n", "SÃ¢u"], value="SÃ¢u")
            else: st.error("ChÆ°a káº¿t ná»‘i API!")

        if st.button("ğŸ—‘ï¸ Reset"): st.session_state.clear(); st.rerun()

    # --- Xá»¬ LÃ Lá»–I QUOTA (HIá»†N LÃŠN Äáº¦U Náº¾U CÃ“ Lá»–I) ---
    if st.session_state.quota_error_state:
        st.markdown("""
        <div class="error-box">
            <h3>âš ï¸ Háº¾T Háº N Má»¨C (QUOTA EXCEEDED)</h3>
            <p>Model hiá»‡n táº¡i Ä‘ang bá»‹ Google giá»›i háº¡n. Báº¡n cÃ³ 2 lá»±a chá»n:</p>
        </div>
        """, unsafe_allow_html=True)
        
        col_retry, col_skip = st.columns(2)
        
        with col_retry:
            rescue_key = st.text_input("ğŸ”‘ Nháº­p API Key riÃªng cá»§a báº¡n Ä‘á»ƒ tiáº¿p tá»¥c dÃ¹ng Model xá»‹n:", type="password", key="rescue_key")
            if st.button("ğŸš€ Thá»­ láº¡i vá»›i Key nÃ y"):
                if rescue_key:
                    if configure_genai(rescue_key):
                        st.session_state.quota_error_state = False # Táº¯t lá»—i
                        # Cháº¡y láº¡i lá»‡nh cÅ© vá»›i key má»›i
                        with st.spinner("Äang cháº¡y láº¡i vá»›i Key má»›i..."):
                            try:
                                model = genai.GenerativeModel(model_version)
                                response = model.generate_content([st.session_state.current_prompt] + st.session_state.gemini_files, generation_config=st.session_state.current_config)
                                st.session_state.analysis_result = response.text
                                st.rerun()
                            except Exception as e:
                                st.error(f"Váº«n lá»—i: {e}")
                    else:
                        st.error("Key khÃ´ng há»£p lá»‡.")
                else:
                    st.warning("Vui lÃ²ng nháº­p Key.")

        with col_skip:
            st.write("Hoáº·c:")
            if st.button("â¬‡ï¸ Bá» qua & DÃ¹ng Model tháº¥p hÆ¡n (1.5 Flash)"):
                st.session_state.quota_error_state = False # Táº¯t lá»—i
                with st.spinner("Äang chuyá»ƒn sang Gemini 1.5 Flash..."):
                    try:
                        # CÆ°á»¡ng Ã©p dÃ¹ng 1.5 Flash
                        fallback_model = genai.GenerativeModel("models/gemini-1.5-flash")
                        response = fallback_model.generate_content([st.session_state.current_prompt] + st.session_state.gemini_files, generation_config=st.session_state.current_config)
                        st.session_state.analysis_result = response.text
                        st.success("ÄÃ£ xá»­ lÃ½ xong báº±ng Gemini 1.5 Flash!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"Lá»—i há»‡ thá»‘ng: {e}")
        
        st.divider() # NgÄƒn cÃ¡ch vá»›i pháº§n dÆ°á»›i

    # --- TABS CHÃNH ---
    tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½", "ğŸ’¬ Chat"])

    with tab_work:
        # Chá»‰ hiá»‡n nÃºt Upload khi KHÃ”NG cÃ³ lá»—i
        if not st.session_state.quota_error_state:
            up_files = st.file_uploader("Upload Audio/PDF/Text", accept_multiple_files=True)
            audio_bytes = audio_recorder()

            if st.button("ğŸš€ Báº®T Äáº¦U THá»°C THI", type="primary"):
                temp_paths = []
                if up_files:
                    for f in up_files:
                        ext = os.path.splitext(f.name)[1] or ".txt"
                        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                            tmp.write(f.getvalue()); temp_paths.append(tmp.name)
                if audio_bytes:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(audio_bytes); temp_paths.append(tmp.name)
                
                if temp_paths:
                    with st.spinner("AI Ä‘ang lÃ m viá»‡c..."):
                        try:
                            g_files = [upload_to_gemini(p) for p in temp_paths]
                            st.session_state.gemini_files = g_files
                            
                            gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2, top_p=0.95)
                            
                            if main_mode.startswith("ğŸ“"):
                                prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: Gá»¡ bÄƒng NGUYÃŠN VÄ‚N 100%. KhÃ´ng tÃ³m táº¯t. Äá»‹nh danh lÃ  'Diá»…n giáº£'."
                            else:
                                prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch sÃ¢u {detail_level}:\n"
                                if opt_summary: prompt += "## TÃ“M Táº®T\n"
                                if opt_action: prompt += "## HÃ€NH Äá»˜NG\n"
                                if opt_process: prompt += "## QUY TRÃŒNH\n"
                                if opt_prosody: prompt += "## Cáº¢M XÃšC\n"
                                if opt_mindmap: prompt += "## MÃƒ SÆ  Äá»’ (Mermaid)\n"
                                if opt_quiz: prompt += "## QUIZ\n"

                            # LÆ¯U Láº I TRáº NG THÃI Äá»‚ RETRY Náº¾U Cáº¦N
                            st.session_state.current_prompt = prompt
                            st.session_state.current_config = gen_config

                            model = genai.GenerativeModel(model_version)
                            response = model.generate_content([prompt] + g_files, generation_config=gen_config)
                            st.session_state.analysis_result = response.text
                            st.success("âœ… HoÃ n thÃ nh.")
                        
                        except Exception as e:
                            # Báº®T Lá»–I QUOTA Táº I ÄÃ‚Y
                            if "429" in str(e) or "Quota" in str(e):
                                st.session_state.quota_error_state = True
                                st.rerun() # Táº£i láº¡i Ä‘á»ƒ hiá»‡n báº£ng nháº­p Key
                            else:
                                st.error(f"Lá»—i: {e}")
                else: st.warning("ChÆ°a cÃ³ file!")

        # HIá»‚N THá»Š Káº¾T QUáº¢
        if st.session_state.analysis_result:
            res = st.session_state.analysis_result
            if "```mermaid" in res:
                try:
                    m_code = res.split("```mermaid")[1].split("```")[0]
                    st_mermaid(m_code, height=500)
                except: pass
            
            sections = res.split("## ")
            for s in sections:
                if not s.strip(): continue
                lines = s.split("\n")
                with st.expander(f"ğŸ“Œ {lines[0].strip()}", expanded=True):
                    st.markdown("\n".join(lines[1:]))

            if main_mode.startswith("ğŸ“") and st.button("â­ï¸ Viáº¿t tiáº¿p Ä‘oáº¡n sau"):
                with st.spinner("Äang nghe tiáº¿p..."):
                    try:
                        cont_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2)
                        model = genai.GenerativeModel(model_version)
                        last_part = res[-300:]
                        c_prompt = f"{STRICT_RULES}\nBáº¡n Ä‘Ã£ viáº¿t Ä‘áº¿n: '{last_part}'. HÃ£y viáº¿t tiáº¿p NGUYÃŠN VÄ‚N Ä‘oáº¡n sau."
                        
                        # LÆ°u tráº¡ng thÃ¡i cho nÃºt tiáº¿p tá»¥c (Ä‘á» phÃ²ng lá»—i quota á»Ÿ Ä‘Ã¢y)
                        st.session_state.current_prompt = c_prompt
                        st.session_state.current_config = cont_config

                        c_res = model.generate_content([c_prompt] + st.session_state.gemini_files, generation_config=cont_config)
                        st.session_state.analysis_result += "\n\n(TIáº¾P THEO)\n\n" + c_res.text
                        st.rerun()
                    except Exception as e:
                        if "429" in str(e):
                            st.session_state.quota_error_state = True
                            st.rerun()
                        else: st.error(f"Lá»—i: {e}")

    with tab_chat:
        st.header("ğŸ’¬ Chat")
        if st.session_state.gemini_files:
            for m in st.session_state.chat_history:
                with st.chat_message(m["role"]): st.markdown(m["content"])
            if inp := st.chat_input("Há»i AI..."):
                st.session_state.chat_history.append({"role": "user", "content": inp})
                with st.chat_message("user"): st.markdown(inp)
                with st.chat_message("assistant"):
                    try:
                        m = genai.GenerativeModel(model_version)
                        r = m.generate_content(st.session_state.gemini_files + [f"TRáº¢ Lá»œI Tá»ª FILE: {inp}"])
                        st.markdown(r.text); st.session_state.chat_history.append({"role": "assistant", "content": r.text})
                    except Exception as e:
                        if "429" in str(e): st.error("Háº¿t Quota! Vui lÃ²ng nháº­p Key á»Ÿ Tab bÃªn cáº¡nh.")
                        else: st.error(f"Lá»—i: {e}")
        else: st.info("ğŸ‘ˆ Upload file trÆ°á»›c.")

if __name__ == "__main__":
    main()
