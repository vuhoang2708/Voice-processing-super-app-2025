import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Universal AI Studio (Final Stable)", page_icon="‚ö°", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: linear-gradient(to right, #c31432, #240b36); color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; background-color: #ffffff;}
    .stMarkdown h2 {font-size: 1.2rem !important; color: #333; border-bottom: 1px solid #eee; padding-bottom: 5px;}
</style>
""", unsafe_allow_html=True)

# --- QU·∫¢N L√ù TR·∫†NG TH√ÅI ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""

# --- H√ÄM H·ªñ TR·ª¢ ---
def configure_genai(user_key=None):
    api_key = None
    if user_key:
        api_key = user_key
    else:
        try:
            if "SYSTEM_KEYS" in st.secrets:
                system_keys = st.secrets["SYSTEM_KEYS"]
                if isinstance(system_keys, str): 
                    clean_str = system_keys.replace('[','').replace(']','').replace('"','').replace("'",'')
                    system_keys = [k.strip() for k in clean_str.split(',') if k.strip()]
                if system_keys: api_key = random.choice(system_keys)
            elif "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
        except: pass
    
    if not api_key: return False

    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_real_models():
    try:
        models = genai.list_models()
        valid_list = []
        for m in models:
            if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name:
                valid_list.append(m.name)
        valid_list.sort(reverse=True)
        
        priority_keywords = ["gemini-3.0-flash", "gemini-2.0-flash-exp", "gemini-1.5-flash"]
        for keyword in priority_keywords:
            found = next((m for m in valid_list if keyword in m), None)
            if found:
                valid_list.insert(0, valid_list.pop(valid_list.index(found)))
                break
        return valid_list
    except:
        return ["models/gemini-1.5-flash", "models/gemini-1.5-pro"]

def get_mime_type(file_path):
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type: return mime_type
    ext = os.path.splitext(file_path)[1].lower()
    if ext == '.pdf': return 'application/pdf'
    if ext == '.txt': return 'text/plain'
    if ext == '.md': return 'text/md'
    if ext == '.csv': return 'text/csv'
    if ext in ['.mp3', '.wav', '.m4a']: return 'audio/mp3'
    return 'application/octet-stream'

def upload_to_gemini(path):
    mime = get_mime_type(path)
    file = genai.upload_file(path, mime_type=mime)
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('B√ÅO C√ÅO PH√ÇN T√çCH AI', 0)
    clean_content = re.sub(r'<[^>]+>', '', content)
    clean_content = re.sub(r'\n\s*\n', '\n\n', clean_content)
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- MAIN APP ---
def main():
    st.title("üáªüá≥ Universal AI Studio (Final Stable)")
    
    # --- SIDEBAR ---
    with st.sidebar:
        st.header("üõ†Ô∏è KHO V≈® KH√ç")
        
        # 1. C·ªêT L√ïI
        st.markdown("### 1. Ph√¢n t√≠ch C·ªët l√µi")
        opt_transcript = st.checkbox("üìù G·ª° bƒÉng (Transcript)", False) 
        opt_summary = st.checkbox("üìã T√≥m t·∫Øt n·ªôi dung", True)
        opt_action = st.checkbox("‚úÖ Action Items", True)
        opt_process = st.checkbox("üîÑ Tr√≠ch xu·∫•t Quy tr√¨nh", False)
        opt_prosody = st.checkbox("üé≠ Ph√¢n t√≠ch Th√°i ƒë·ªô", False)
        opt_gossip = st.checkbox("‚òï Ch·∫ø ƒë·ªô B√† t√°m", False)

        # 2. S√ÅNG T·∫†O
        st.markdown("### 2. S√°ng t·∫°o Nghe/Nh√¨n")
        opt_podcast = st.checkbox("üéôÔ∏è K·ªãch b·∫£n Podcast", False)
        opt_video = st.checkbox("üé¨ K·ªãch b·∫£n Video", False)
        opt_mindmap = st.checkbox("üß† S∆° ƒë·ªì t∆∞ duy", True)

        # 3. NGHI√äN C·ª®U
        st.markdown("### 3. H·ªçc t·∫≠p & Nghi√™n c·ª©u")
        opt_report = st.checkbox("üìë B√°o c√°o chuy√™n s√¢u", False)
        opt_briefing = st.checkbox("üìÑ T√†i li·ªáu t√≥m l∆∞·ª£c", False)
        opt_timeline = st.checkbox("‚è≥ D√≤ng th·ªùi gian", False)
        opt_quiz = st.checkbox("‚ùì C√¢u h·ªèi Tr·∫Øc nghi·ªám", False)
        opt_flashcard = st.checkbox("üé¥ Th·∫ª ghi nh·ªõ", False)
        
        # 4. D·ªÆ LI·ªÜU
        st.markdown("### 4. D·ªØ li·ªáu")
        opt_infographic = st.checkbox("üìä D·ªØ li·ªáu Infographic", False)
        opt_slides = st.checkbox("üñ•Ô∏è D√†n √Ω Slide", False)
        opt_table = st.checkbox("üìâ B·∫£ng s·ªë li·ªáu", False)

        st.divider()
        
        # C·∫§U H√åNH ·∫®N
        with st.expander("‚öôÔ∏è C·∫•u h√¨nh & API Key"):
            user_api_key = st.text_input("Nh·∫≠p Key ri√™ng:", type="password")
            is_connected = configure_genai(user_api_key)
            if is_connected:
                st.success("ƒê√£ k·∫øt n·ªëi!")
                real_models = get_real_models()
                model_version = st.selectbox("Model:", real_models, index=0)
                detail_level = st.select_slider("ƒê·ªô chi ti·∫øt:", options=["S∆° l∆∞·ª£c", "Ti√™u chu·∫©n", "Chi ti·∫øt s√¢u"], value="Ti√™u chu·∫©n")
            else:
                st.error("Ch∆∞a k·∫øt n·ªëi!")
                model_version = "models/gemini-1.5-flash"
                detail_level = "Ti√™u chu·∫©n"

        if st.button("üóëÔ∏è Reset"):
            st.session_state.clear()
            st.rerun()

    # --- GIAO DI·ªÜN TAB ---
    tab1, tab2 = st.tabs(["üìÇ Upload & Ph√¢n t√≠ch", "üí¨ Chat Ti·∫øng Vi·ªát"])

    # === TAB 1 ===
    with tab1:
        col_up, col_rec = st.columns(2)
        with col_up:
            st.subheader("1. Upload File")
            uploaded_files = st.file_uploader("Ch·ªçn file (Audio, PDF, Text...)", type=['mp3', 'wav', 'm4a', 'pdf', 'txt', 'md', 'csv'], accept_multiple_files=True)
        with col_rec:
            st.subheader("2. Ghi √¢m")
            audio_bytes = audio_recorder()

        if st.button("üî• B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH", type="primary"):
            temp_paths = []
            if uploaded_files:
                for up_file in uploaded_files:
                    file_ext = os.path.splitext(up_file.name)[1]
                    if not file_ext: file_ext = ".txt"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
                        tmp.write(up_file.getvalue())
                        temp_paths.append(tmp.name)
            if audio_bytes:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_bytes)
                    temp_paths.append(tmp.name)
            
            if not temp_paths:
                st.warning("Vui l√≤ng ch·ªçn file!")
            else:
                with st.spinner(f"ƒêang x·ª≠ l√Ω {len(temp_paths)} file..."):
                    try:
                        gemini_files_objs = []
                        for path in temp_paths:
                            g_file = upload_to_gemini(path)
                            gemini_files_objs.append(g_file)
                            os.remove(path)
                        
                        st.session_state.gemini_files = gemini_files_objs
                        
                        # --- X√ÇY D·ª∞NG PROMPT ---
                        length_instruction = "Vi·∫øt chi ti·∫øt, ƒë·∫ßy ƒë·ªß." if detail_level == "Chi ti·∫øt s√¢u" else "Vi·∫øt ng·∫Øn g·ªçn."
                        
                        base_prompt = f"""
                        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch. Nhi·ªám v·ª•: X·ª≠ l√Ω file v√† t·∫°o b√°o c√°o Ti·∫øng Vi·ªát.
                        QUY T·∫ÆC:
                        1. B·∫Øt ƒë·∫ßu m·ªói m·ª•c b·∫±ng ti√™u ƒë·ªÅ H2 (##) CH√çNH X√ÅC.
                        2. KH√îNG d√πng H2 cho n·ªôi dung con.
                        3. KH√îNG tr·∫£ v·ªÅ XML.
                        4. {length_instruction}
                        """
                        
                        tasks = []
                        if opt_transcript: tasks.append("## 0. G·ª† BƒÇNG CHI TI·∫æT (TRANSCRIPT)\n- Ghi l·∫°i nguy√™n vƒÉn h·ªôi tho·∫°i.\n")
                        if opt_summary: tasks.append("## 1. T√ìM T·∫ÆT N·ªòI DUNG\n- T√≥m t·∫Øt c√°c √Ω ch√≠nh quan tr·ªçng.\n")
                        if opt_action: tasks.append("## 2. DANH S√ÅCH H√ÄNH ƒê·ªòNG (ACTION ITEMS)\n- Ai l√†m g√¨, deadline khi n√†o.\n")
                        if opt_process: tasks.append("## 3. QUY TR√åNH TH·ª∞C HI·ªÜN\n- C√°c b∆∞·ªõc step-by-step.\n")
                        if opt_prosody: tasks.append("## 4. PH√ÇN T√çCH TH√ÅI ƒê·ªò\n- C·∫£m x√∫c, ng·ªØ ƒëi·ªáu ng∆∞·ªùi n√≥i.\n")
                        if opt_gossip: tasks.append("## 5. G√ìC B√Ä T√ÅM\n- K·ªÉ chuy·ªán h√†i h∆∞·ªõc.\n")
                        if opt_podcast: tasks.append("## 6. K·ªäCH B·∫¢N PODCAST\n- ƒê·ªëi tho·∫°i Host/Guest.\n")
                        if opt_video: tasks.append("## 7. K·ªäCH B·∫¢N VIDEO\n- Chia 2 c·ªôt H√¨nh/Ti·∫øng.\n")
                        if opt_mindmap: tasks.append("## 8. M√É S∆† ƒê·ªí T∆Ø DUY (MERMAID)\n- Ch·ªâ tr·∫£ v·ªÅ code trong block ```mermaid```.\n")
                        if opt_report: tasks.append("## 9. B√ÅO C√ÅO CHUY√äN S√ÇU\n- VƒÉn phong h√†nh ch√≠nh.\n")
                        if opt_briefing: tasks.append("## 10. T√ÄI LI·ªÜU T√ìM L∆Ø·ª¢C\n- B·∫£n brief ng·∫Øn.\n")
                        if opt_timeline: tasks.append("## 11. D√íNG TH·ªúI GIAN\n- C√°c m·ªëc s·ª± ki·ªán.\n")
                        if opt_quiz: tasks.append("## 12. C√ÇU H·ªéI TR·∫ÆC NGHI·ªÜM\n- 5 c√¢u h·ªèi c√≥ ƒë√°p √°n.\n")
                        if opt_flashcard: tasks.append("## 13. TH·∫∫ GHI NH·ªö (FLASHCARDS)\n- Thu·∫≠t ng·ªØ v√† ƒë·ªãnh nghƒ©a.\n")
                        if opt_infographic: tasks.append("## 14. D·ªÆ LI·ªÜU INFOGRAPHIC\n- S·ªë li·ªáu ƒëi·ªÉm nh·∫•n.\n")
                        if opt_slides: tasks.append("## 15. D√ÄN √ù SLIDE\n- C·∫•u tr√∫c b√†i thuy·∫øt tr√¨nh.\n")
                        if opt_table: tasks.append("## 16. B·∫¢NG S·ªê LI·ªÜU\n- B·∫£ng Markdown.\n")

                        final_prompt = base_prompt + "\n" + "".join(tasks)

                        generation_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.5)
                        model = genai.GenerativeModel(model_version)
                        response = model.generate_content([final_prompt] + gemini_files_objs, generation_config=generation_config)
                        
                        st.session_state.analysis_result = response.text
                        st.success("‚úÖ X·ª≠ l√Ω xong!")
                    except Exception as e:
                        st.error(f"L·ªói: {e}")

        # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
        if st.session_state.analysis_result:
            st.divider()
            full_text = st.session_state.analysis_result
            
            doc = create_docx(full_text)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("üì• T·∫£i B√°o C√°o (.docx)", f, "Bao_Cao_AI.docx", type="primary")
            os.remove(doc_io.name)
            
            st.markdown("### üîç K·∫æT QU·∫¢ CHI TI·∫æT")
            
            sections = full_text.split("## ")
            for section in sections:
                section = section.strip()
                if not section: continue
                
                lines = section.split("\n")
                title = lines[0].strip()
                content = "\n".join(lines[1:]).strip()
                
                if not content or content.startswith("<"): continue

                if "MERMAID" in title.upper() or "S∆† ƒê·ªí" in title.upper():
                    with st.expander(f"üß† {title}", expanded=True):
                        try:
                            mermaid_code = content.split("```mermaid")[1].split("```")[0]
                            st_mermaid(mermaid_code, height=500)
                            st.code(mermaid_code, language="mermaid")
                        except: st.markdown(content)
                else:
                    with st.expander(f"üìå {title}", expanded=False):
                        st.markdown(content)

    # === TAB 2 ===
    with tab2:
        st.header("üí¨ Chat v·ªõi D·ªØ li·ªáu")
        if not st.session_state.gemini_files:
            st.info("üëà Vui l√≤ng Upload file ·ªü Tab 1 tr∆∞·ªõc.")
        else:
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if user_input := st.chat_input("H·ªèi chi ti·∫øt..."):
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                with st.chat_message("user"): st.markdown(user_input)
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        try:
                            chat_model = genai.GenerativeModel(model_version)
                            response = chat_model.generate_content(st.session_state.gemini_files + [f"Tr·∫£ l·ªùi Ti·∫øng Vi·ªát: {user_input}"])
                            st.markdown(response.text)
                            st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                        except Exception as e: st.error(f"L·ªói: {e}")

if __name__ == "__main__":
    main()
