import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio Pro", page_icon="ğŸ›¡ï¸", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: linear-gradient(to right, #2c3e50, #000000); color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px;}
    .stMarkdown h2 {color: #1a2a6c; border-bottom: 2px solid #eee; padding-bottom: 5px;}
</style>
""", unsafe_allow_html=True)

# --- QUáº¢N LÃ SESSION STATE ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""

# --- HÃ€M Há»– TRá»¢ ---
def configure_genai(user_key=None):
    api_key = user_key or st.secrets.get("GOOGLE_API_KEY") or (random.choice(st.secrets["SYSTEM_KEYS"]) if "SYSTEM_KEYS" in st.secrets else None)
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_real_models():
    try:
        models = genai.list_models()
        valid_list = [m.name for m in models if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name]
        valid_list.sort(reverse=True)
        # Æ¯u tiÃªn 3.0 Flash lÃªn Ä‘áº§u
        for kw in ["gemini-3.0-flash", "gemini-2.0-flash", "gemini-1.5-flash"]:
            found = [m for m in valid_list if kw in m]
            if found:
                valid_list.insert(0, valid_list.pop(valid_list.index(found[0])))
                break
        return valid_list
    except: return ["models/gemini-1.5-flash"]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

# --- MAIN APP ---
def main():
    st.title("ğŸ›¡ï¸ AI Studio Pro (Hallucination-Free Edition)")
    
    # --- SIDEBAR: KHO VÅ¨ KHÃ ---
    with st.sidebar:
        st.header("ğŸ› ï¸ KHO VÅ¨ KHÃ")
        main_mode = st.radio("Má»¥c tiÃªu chÃ­nh:", ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn (Transcript)", "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u (Analysis)"))
        
        if main_mode == "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u (Analysis)":
            st.subheader("TÃ­nh nÄƒng:")
            c1, c2 = st.columns(2)
            with c1:
                opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t", True)
                opt_action = st.checkbox("âœ… HÃ nh Ä‘á»™ng", True)
                opt_process = st.checkbox("ğŸ”„ Quy trÃ¬nh", False)
            with c2:
                opt_prosody = st.checkbox("ğŸ­ Cáº£m xÃºc", False)
                opt_mindmap = st.checkbox("ğŸ§  Mindmap", True)
                opt_quiz = st.checkbox("â“ Quiz/Slide", False)
        
        st.divider()
        with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & Key"):
            user_key = st.text_input("Nháº­p Key riÃªng:", type="password")
            if configure_genai(user_key):
                st.success("ÄÃ£ káº¿t ná»‘i!")
                models = get_real_models()
                model_version = st.selectbox("Engine:", models, index=0)
                detail_level = st.select_slider("Äá»™ chi tiáº¿t:", options=["SÆ¡ lÆ°á»£c", "TiÃªu chuáº©n", "SÃ¢u"], value="SÃ¢u")
            else: st.error("ChÆ°a káº¿t ná»‘i API!")

        if st.button("ğŸ—‘ï¸ Reset"):
            st.session_state.clear(); st.rerun()

    tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½", "ğŸ’¬ Chat"])

    with tab_work:
        up_files = st.file_uploader("Upload Audio/PDF/Text", accept_multiple_files=True)
        audio_bytes = audio_recorder()

        if st.button("ğŸš€ Báº®T Äáº¦U", type="primary"):
            temp_paths = []
            if up_files:
                for f in up_files:
                    ext = os.path.splitext(f.name)[1] or ".txt"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                        tmp.write(f.getvalue()); temp_paths.append(tmp.name)
            if audio_bytes:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_bytes); temp_paths.append(tmp.name)
            
            if temp_paths:
                with st.spinner("AI Ä‘ang Ä‘á»‘i chiáº¿u dá»¯ liá»‡u gá»‘c..."):
                    try:
                        g_files = [upload_to_gemini(p) for p in temp_paths]
                        st.session_state.gemini_files = g_files
                        
                        # Cáº¤U HÃŒNH CHá»NG Bá»ŠA CHUYá»†N TUYá»†T Äá»I
                        gen_config = genai.types.GenerationConfig(
                            max_output_tokens=8192,
                            temperature=0.0, # KHÃ”NG SÃNG Táº O
                            top_p=0.1,       # CHá»ˆ CHá»ŒN ÄÃP ÃN CHáº®C CHáº®N NHáº¤T
                        )
                        
                        common_rules = """
                        NGUYÃŠN Táº®C 'GROUNDING' Báº®T BUá»˜C:
                        1. CHá»ˆ Sá»¬ Dá»¤NG thÃ´ng tin cÃ³ trong cÃ¡c file Ä‘Æ°á»£c cung cáº¥p.
                        2. TUYá»†T Äá»I KHÃ”NG sá»­ dá»¥ng kiáº¿n thá»©c bÃªn ngoÃ i hoáº·c dá»± Ä‘oÃ¡n thÃ´ng tin thiáº¿u.
                        3. Náº¿u thÃ´ng tin khÃ´ng cÃ³ trong file, pháº£i tráº£ lá»i lÃ  'Ná»™i dung nÃ y khÃ´ng cÃ³ trong dá»¯ liá»‡u gá»‘c'.
                        4. TUYá»†T Äá»I KHÃ”NG Ä‘oÃ¡n tÃªn ngÆ°á»i, tÃªn cÃ´ng ty hay Ä‘á»‹a danh náº¿u khÃ´ng Ä‘Æ°á»£c xÆ°ng danh rÃµ rÃ ng trong file.
                        5. Cung cáº¥p má»‘c thá»i gian [phÃºt:giÃ¢y] cho má»i luáº­n Ä‘iá»ƒm quan trá»ng.
                        """

                        if main_mode.startswith("ğŸ“"):
                            prompt = f"{common_rules}\nNHIá»†M Vá»¤: Gá»¡ bÄƒng nguyÃªn vÄƒn (Verbatim) tá»«ng lá»i nÃ³i. KhÃ´ng tÃ³m táº¯t. Viáº¿t Tiáº¿ng Viá»‡t."
                        else:
                            prompt = f"{common_rules}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch chuyÃªn sÃ¢u (Äá»™ chi tiáº¿t: {detail_level}).\n"
                            if opt_summary: prompt += "## TÃ“M Táº®T Ná»˜I DUNG\n"
                            if opt_action: prompt += "## HÃ€NH Äá»˜NG Cáº¦N LÃ€M\n"
                            if opt_process: prompt += "## QUY TRÃŒNH\n"
                            if opt_prosody: prompt += "## THÃI Äá»˜ NGá»® ÄIá»†U\n"
                            if opt_mindmap: prompt += "## MÃƒ SÆ  Äá»’ (Mermaid block)\n"
                            if opt_quiz: prompt += "## QUIZ & SLIDE OUTLINE\n"

                        model = genai.GenerativeModel(model_version)
                        response = model.generate_content([prompt] + g_files, generation_config=gen_config)
                        st.session_state.analysis_result = response.text
                        st.success("âœ… ÄÃ£ hoÃ n thÃ nh xá»­ lÃ½ an toÃ n.")
                    except Exception as e: st.error(f"Lá»—i: {e}")
            else: st.warning("ChÆ°a cÃ³ file!")

        if st.session_state.analysis_result:
            res = st.session_state.analysis_result
            if "```mermaid" in res:
                try:
                    m_code = res.split("```mermaid")[1].split("```")[0]
                    st_mermaid(m_code, height=500)
                except: pass
            
            sections = res.split("## ")
            for s in sections:
                if not s.strip(): continue
                lines = s.split("\n")
                with st.expander(f"ğŸ“Œ {lines[0].strip()}", expanded=True):
                    st.markdown("\n".join(lines[1:]))

            if main_mode.startswith("ğŸ“") and st.button("â­ï¸ Tiáº¿p tá»¥c Ä‘oáº¡n sau (Náº¿u bá»‹ ngáº¯t)"):
                with st.spinner("Äang nghe tiáº¿p..."):
                    model = genai.GenerativeModel(model_version)
                    c_prompt = f"Tiáº¿p tá»¥c gá»¡ bÄƒng NGUYÃŠN VÄ‚N Ä‘oáº¡n tiáº¿p theo cá»§a file. Báº¯t Ä‘áº§u ngay sau Ä‘oáº¡n: '{res[-200:]}'"
                    c_res = model.generate_content([c_prompt] + st.session_state.gemini_files, generation_config=gen_config)
                    st.session_state.analysis_result += "\n\n--- PHáº¦N TIáº¾P THEO ---\n\n" + c_res.text
                    st.rerun()

    with tab_chat:
        st.header("ğŸ’¬ Chat báº£o máº­t")
        if st.session_state.gemini_files:
            for m in st.session_state.chat_history:
                with st.chat_message(m["role"]): st.markdown(m["content"])
            if inp := st.chat_input("Há»i AI..."):
                st.session_state.chat_history.append({"role": "user", "content": inp})
                with st.chat_message("user"): st.markdown(inp)
                with st.chat_message("assistant"):
                    m = genai.GenerativeModel(model_version)
                    r = m.generate_content(st.session_state.gemini_files + [f"TRáº¢ Lá»œI DUY NHáº¤T Tá»ª FILE, TEMPERATURE 0: {inp}"])
                    st.markdown(r.text)
                    st.session_state.chat_history.append({"role": "assistant", "content": r.text})
        else: st.info("ğŸ‘ˆ Upload file trÆ°á»›c.")

if __name__ == "__main__":
    main()
