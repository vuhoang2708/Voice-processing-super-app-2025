import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random

# --- Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio Pro", page_icon="ğŸš€", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: linear-gradient(to right, #1e3c72, #2a5298); color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; background-color: #ffffff;}
    .stMarkdown h2 {font-size: 1.2rem !important; color: #1e3c72; border-bottom: 2px solid #eee; padding-bottom: 5px;}
    .stRadio > label {font-weight: bold; color: #d32f2f;}
</style>
""", unsafe_allow_html=True)

# --- QUáº¢N LÃ TRáº NG THÃI ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""

# --- HÃ€M Há»– TRá»¢ ---
def configure_genai(user_key=None):
    api_key = None
    if user_key:
        api_key = user_key
    else:
        try:
            if "SYSTEM_KEYS" in st.secrets:
                system_keys = st.secrets["SYSTEM_KEYS"]
                if isinstance(system_keys, str): 
                    clean_str = system_keys.replace('[','').replace(']','').replace('"','').replace("'",'')
                    system_keys = [k.strip() for k in clean_str.split(',') if k.strip()]
                if system_keys: api_key = random.choice(system_keys)
            elif "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
        except: pass
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_real_models():
    try:
        models = genai.list_models()
        valid_list = [m.name for m in models if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name]
        valid_list.sort(reverse=True)
        # Æ¯u tiÃªn Flash 3.0/2.0 Preview lÃªn Ä‘áº§u
        for keyword in ["gemini-3.0-flash", "gemini-2.0-flash-exp", "gemini-1.5-flash"]:
            found = next((m for m in valid_list if keyword in m), None)
            if found:
                valid_list.insert(0, valid_list.pop(valid_list.index(found)))
                break
        return valid_list
    except:
        return ["models/gemini-1.5-flash"]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def create_docx(content):
    doc = Document()
    doc.add_heading('BÃO CÃO PHÃ‚N TÃCH AI CHUYÃŠN NGHIá»†P', 0)
    clean_content = re.sub(r'<[^>]+>', '', content)
    for line in clean_content.split('\n'):
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), level=1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), level=2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), level=3)
        else: doc.add_paragraph(line)
    return doc

# --- MAIN APP ---
def main():
    st.title("ğŸŒŒ Universal AI Studio (Pro Mode)")
    
    # --- SIDEBAR ---
    with st.sidebar:
        st.header("ğŸ¯ CHáº¾ Äá»˜ HOáº T Äá»˜NG")
        
        # Sá»¬ Dá»¤NG RADIO BUTTON Äá»‚ TÃCH BIá»†T NHIá»†M Vá»¤
        main_mode = st.radio(
            "Chá»n má»¥c tiÃªu chÃ­nh cá»§a báº¡n:",
            ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn (Full Transcript)", "ğŸ“Š Bá»™ vÅ© khÃ­ phÃ¢n tÃ­ch (Deep Analysis)"),
            help="LÆ°u Ã½: Cháº¿ Ä‘á»™ Gá»¡ bÄƒng sáº½ Æ°u tiÃªn chÃ©p lá»i chÃ­nh xÃ¡c nháº¥t. Cháº¿ Ä‘á»™ PhÃ¢n tÃ­ch sáº½ dÃ¹ng cÃ¡c cÃ´ng cá»¥ chuyÃªn sÃ¢u."
        )

        st.divider()

        if main_mode == "ğŸ“Š Bá»™ vÅ© khÃ­ phÃ¢n tÃ­ch (Deep Analysis)":
            st.subheader("ğŸ› ï¸ CHá»ŒN CÃC VÅ¨ KHÃ PHÃ‚N TÃCH")
            col_a, col_b = st.columns(2)
            with col_a:
                opt_summary = st.checkbox("ğŸ“‹ TÃ³m táº¯t Ã½", True)
                opt_action = st.checkbox("âœ… HÃ nh Ä‘á»™ng", True)
                opt_process = st.checkbox("ğŸ”„ Quy trÃ¬nh", False)
                opt_prosody = st.checkbox("ğŸ­ Cáº£m xÃºc", False)
            with col_b:
                opt_gossip = st.checkbox("â˜• BÃ  tÃ¡m", False)
                opt_mindmap = st.checkbox("ğŸ§  Mindmap", True)
                opt_quiz = st.checkbox("â“ Tráº¯c nghiá»‡m", False)
                opt_slides = st.checkbox("ğŸ–¥ï¸ DÃ n Ã½ Slide", False)
        else:
            st.info("ğŸ’¡ Cháº¿ Ä‘á»™ Gá»¡ bÄƒng sáº½ tá»± Ä‘á»™ng táº¯t cÃ¡c tÃ­nh nÄƒng phÃ¢n tÃ­ch Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ dÃ i vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a vÄƒn báº£n.")

        st.divider()
        
        # Cáº¤U HÃŒNH XUá»NG ÄÃY
        with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & API Key (NÃ¢ng cao)"):
            user_api_key = st.text_input("Nháº­p Key riÃªng:", type="password")
            if configure_genai(user_api_key):
                st.success("ÄÃ£ káº¿t ná»‘i!")
                real_models = get_real_models()
                model_version = st.selectbox("Chá»n Engine (Máº·c Ä‘á»‹nh Flash 3/2):", real_models, index=0)
                detail_level = st.select_slider("Äá»™ chi tiáº¿t:", options=["SÆ¡ lÆ°á»£c", "TiÃªu chuáº©n", "Chi tiáº¿t sÃ¢u"], value="Chi tiáº¿t sÃ¢u")
            else:
                st.error("ChÆ°a káº¿t ná»‘i!")
                model_version = "models/gemini-1.5-flash"
                detail_level = "TiÃªu chuáº©n"

        if st.button("ğŸ—‘ï¸ Reset App"):
            st.session_state.clear()
            st.rerun()

    # --- GIAO DIá»†N CHÃNH ---
    tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½ Dá»¯ liá»‡u", "ğŸ’¬ Chat ChuyÃªn sÃ¢u"])

    with tab_work:
        col1, col2 = st.columns(2)
        with col1: uploaded_files = st.file_uploader("Upload file (Audio, PDF, Text...)", type=['mp3', 'wav', 'm4a', 'pdf', 'txt', 'md', 'csv'], accept_multiple_files=True)
        with col2: audio_bytes = audio_recorder()

        if st.button("ğŸš€ Báº®T Äáº¦U THá»°C THI", type="primary"):
            temp_paths = []
            if uploaded_files:
                for up_file in uploaded_files:
                    file_ext = os.path.splitext(up_file.name)[1] or ".txt"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp:
                        tmp.write(up_file.getvalue())
                        temp_paths.append(tmp.name)
            if audio_bytes:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(audio_bytes)
                    temp_paths.append(tmp.name)
            
            if not temp_paths:
                st.warning("Vui lÃ²ng cung cáº¥p dá»¯ liá»‡u Ä‘áº§u vÃ o!")
            else:
                with st.spinner(f"AI Ä‘ang thá»±c hiá»‡n cháº¿ Ä‘á»™: {main_mode}..."):
                    try:
                        gemini_files_objs = []
                        for path in temp_paths:
                            g_file = upload_to_gemini(path)
                            gemini_files_objs.append(g_file)
                            os.remove(path)
                        
                        st.session_state.gemini_files = gemini_files_objs

                        # --- LOGIC PROMPT BIáº¾N THIÃŠN ---
                        if main_mode == "ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn (Full Transcript)":
                            prompt = """
                            Báº N LÃ€ THÆ¯ KÃ TÃ’A ÃN CHUYÃŠN NGHIá»†P. 
                            NHIá»†M Vá»¤ Tá»I THÆ¯á»¢NG: Nghe vÃ  chÃ©p láº¡i NGUYÃŠN VÄ‚N (Verbatim) tá»«ng lá»i nÃ³i trong file Ã¢m thanh/tÃ i liá»‡u.
                            YÃŠU Cáº¦U:
                            - KHÃ”NG ÄÆ¯á»¢C TÃ“M Táº®T.
                            - KHÃ”NG ÄÆ¯á»¢C Bá» SÃ“T cÃ¡c cÃ¢u chuyá»‡n ká»ƒ, vÃ­ dá»¥, lá»i Ä‘Ã¹a hay dáº«n chá»©ng.
                            - Ghi rÃµ tÃªn ngÆ°á»i nÃ³i (náº¿u nháº­n diá»‡n Ä‘Æ°á»£c) vÃ  má»‘c thá»i gian [phÃºt:giÃ¢y].
                            - Sá»­ dá»¥ng 100% Tiáº¿ng Viá»‡t chuáº©n.
                            - Viáº¿t dÃ i vÃ  chi tiáº¿t nháº¥t cÃ³ thá»ƒ.
                            Báº¯t Ä‘áº§u báº±ng tiÃªu Ä‘á»: ## 0. Báº¢N Gá»  BÄ‚NG CHI TIáº¾T
                            """
                        else:
                            prompt = f"Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch dá»¯ liá»‡u. HÃ£y thá»±c hiá»‡n cÃ¡c má»¥c sau (Äá»™ chi tiáº¿t: {detail_level}):\n"
                            if opt_summary: prompt += "## 1. TÃ“M Táº®T Ã CHÃNH\n"
                            if opt_action: prompt += "## 2. DANH SÃCH HÃ€NH Äá»˜NG (ACTION ITEMS)\n"
                            if opt_process: prompt += "## 3. QUY TRÃŒNH THá»°C HIá»†N\n"
                            if opt_prosody: prompt += "## 4. PHÃ‚N TÃCH TÃ‚M LÃ & NGá»® ÄIá»†U\n"
                            if opt_gossip: prompt += "## 5. GÃ“C BÃ€ TÃM (CHUYá»†N BÃŠN Lá»€)\n"
                            if opt_mindmap: prompt += "## 6. MÃƒ SÆ  Äá»’ TÆ¯ DUY\n(Chá»‰ tráº£ vá» code mermaid trong block ```mermaid```)\n"
                            if opt_quiz: prompt += "## 7. CÃ‚U Há»I KIá»‚M TRA & THáºº NHá»š\n"
                            if opt_slides: prompt += "## 8. DÃ€N Ã BÃ€I THUYáº¾T TRÃŒNH\n"

                        model = genai.GenerativeModel(model_version)
                        # TÄƒng giá»›i háº¡n tá»‘i Ä‘a cho báº£n gá»¡ bÄƒng
                        config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.3)
                        response = model.generate_content([prompt] + gemini_files_objs, generation_config=config)
                        
                        st.session_state.analysis_result = response.text
                        st.success("âœ… ÄÃ£ hoÃ n thÃ nh!")
                    except Exception as e:
                        st.error(f"Lá»—i há»‡ thá»‘ng: {e}")

        if st.session_state.analysis_result:
            st.divider()
            full_text = st.session_state.analysis_result
            
            # Táº£i vá»
            doc = create_docx(full_text)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("ğŸ“¥ Táº£i BÃ¡o CÃ¡o (.docx)", f, "Bao_Cao_AI_Pro.docx", type="primary")
            os.remove(doc_io.name)
            
            # Hiá»ƒn thá»‹
            sections = full_text.split("## ")
            for section in sections:
                if not section.strip(): continue
                lines = section.split("\n")
                title = lines[0].strip()
                content = "\n".join(lines[1:]).strip()
                if not content or content.startswith("<"): continue

                if "MERMAID" in title.upper() or "SÆ  Äá»’" in title.upper():
                    with st.expander(f"ğŸ§  {title}", expanded=True):
                        try:
                            mermaid_code = content.split("```mermaid")[1].split("```")[0]
                            st_mermaid(mermaid_code, height=500)
                        except: st.markdown(content)
                else:
                    with st.expander(f"ğŸ“Œ {title}", expanded=True if main_mode.startswith("ğŸ“") else False):
                        st.markdown(content)

    with tab_chat:
        st.header("ğŸ’¬ Chat vá»›i Dá»¯ liá»‡u")
        if not st.session_state.gemini_files:
            st.info("ğŸ‘ˆ Upload file á»Ÿ Tab 1 trÆ°á»›c.")
        else:
            for msg in st.session_state.chat_history:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if user_input := st.chat_input("Há»i chi tiáº¿t vá» ná»™i dung..."):
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                with st.chat_message("user"): st.markdown(user_input)
                with st.chat_message("assistant"):
                    with st.spinner("Äang tráº£ lá»i..."):
                        try:
                            chat_model = genai.GenerativeModel(model_version)
                            response = chat_model.generate_content(st.session_state.gemini_files + [f"Tráº£ lá»i Tiáº¿ng Viá»‡t: {user_input}"])
                            st.markdown(response.text)
                            st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                        except Exception as e: st.error(f"Lá»—i: {e}")

if __name__ == "__main__":
    main()
