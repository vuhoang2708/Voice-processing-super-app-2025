import streamlit as st
import google.generativeai as genai
from docx import Document
from streamlit_mermaid import st_mermaid
from audio_recorder_streamlit import audio_recorder
import tempfile
import os
import time
import mimetypes
import re
import random
import shutil

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="Universal AI Studio (Pro)", page_icon="ğŸ›¡ï¸", layout="wide")
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 8px; height: 3em; font-weight: bold; background: #1e3c72; color: white;}
    .stExpander {border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 10px; background-color: #ffffff;}
    .stMarkdown h2 {color: #1a2a6c; border-bottom: 2px solid #eee; padding-bottom: 5px;}
    div[data-testid="stButton"] > button:contains("Dá»ªNG") {background-color: #d32f2f !important;}
</style>
""", unsafe_allow_html=True)

# --- 2. BIáº¾N TOÃ€N Cá»¤C & Cáº¤U HÃŒNH ---
STRICT_RULES = "CHá»ˆ DÃ™NG FILE Gá»C. Cáº¤M Bá»ŠA TÃŠN DIá»„N GIáº¢. Cáº¤M Bá»ŠA Ná»˜I DUNG. TRÃCH DáºªN GIá»œ [mm:ss]."
MAX_LOOPS = 20  # Giá»›i háº¡n an toÃ n: khoáº£ng 2 tiáº¿ng audio Ä‘á»ƒ trÃ¡nh treo mÃ¡y

# --- 3. QUáº¢N LÃ SESSION ---
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "gemini_files" not in st.session_state: st.session_state.gemini_files = [] 
if "local_files" not in st.session_state: st.session_state.local_files = [] # Theo dÃµi file táº¡m
if "analysis_result" not in st.session_state: st.session_state.analysis_result = ""
if "is_auto_running" not in st.session_state: st.session_state.is_auto_running = False
if "loop_count" not in st.session_state: st.session_state.loop_count = 0

# --- 4. HÃ€M Há»– TRá»¢ Ká»¸ THUáº¬T ---

def cleanup_resources():
    """Dá»n dáº¹p tÃ i nguyÃªn trÃªn Cloud vÃ  Local Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»›"""
    # 1. XÃ³a file trÃªn Google Cloud
    if st.session_state.gemini_files:
        for f in st.session_state.gemini_files:
            try:
                genai.delete_file(f.name)
            except Exception: pass
    
    # 2. XÃ³a file táº¡m trÃªn á»• cá»©ng server
    if st.session_state.local_files:
        for p in st.session_state.local_files:
            try:
                if os.path.exists(p): os.remove(p)
            except Exception: pass
            
    st.session_state.gemini_files = []
    st.session_state.local_files = []

def configure_genai(user_key=None):
    api_key = user_key
    if not api_key:
        try:
            if "SYSTEM_KEYS" in st.secrets:
                keys = st.secrets["SYSTEM_KEYS"]
                if isinstance(keys, str): 
                    keys = [k.strip() for k in keys.replace('[','').replace(']','').replace('"','').replace("'",'').split(',')]
                if keys: api_key = random.choice(keys)
            elif "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
        except: pass
    
    if not api_key: return False
    try:
        genai.configure(api_key=api_key)
        return True
    except: return False

def get_optimized_models():
    # Danh sÃ¡ch cá»©ng: ÄÃ£ cáº­p nháº­t theo chá»‰ Ä‘áº¡o cá»§a bÃ¡c
    return [
        "models/gemini-3.0-flash-preview", # Æ¯u tiÃªn sá»‘ 1: Model bÃ¡c Ä‘ang dÃ¹ng ngon
        "models/gemini-2.0-flash-exp",    # Báº£n Flash Next Gen (Experimental)
        "models/gemini-1.5-pro",          # Báº£n Pro á»•n Ä‘á»‹nh
        "models/gemini-1.5-flash",        # Báº£n Backup tiáº¿t kiá»‡m
        "models/gemini-1.5-pro-002",      # Báº£n Pro cáº­p nháº­t
    ]

def upload_to_gemini(path):
    mime_type, _ = mimetypes.guess_type(path)
    file = genai.upload_file(path, mime_type=mime_type or "application/octet-stream")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    return file

def get_smart_anchor(text, char_limit=1000):
    """Láº¥y má» neo thÃ´ng minh: Cáº¯t Ä‘Ãºng dáº¥u cháº¥m cÃ¢u Ä‘á»ƒ AI khÃ´ng bá»‹ loáº¡n"""
    anchor = text[-char_limit:]
    # TÃ¬m dáº¥u cháº¥m cÃ¢u (.!?) hoáº·c xuá»‘ng dÃ²ng gáº§n nháº¥t
    match = re.search(r'[.!?\n]', anchor)
    if match:
        return anchor[match.start()+1:].strip()
    return anchor # Fallback náº¿u khÃ´ng tÃ¬m tháº¥y

def create_docx(content):
    """Táº¡o file Word sáº¡ch, loáº¡i bá» kÃ½ tá»± Markdown thá»«a"""
    doc = Document()
    doc.add_heading('BÃO CÃO Gá»  BÄ‚NG (AI STUDIO)', 0)
    
    clean_content = content.replace("```markdown", "").replace("```", "")
    
    for line in clean_content.split('\n'):
        # Loáº¡i bá» cÃ¡c kÃ½ tá»± format Markdown cÆ¡ báº£n Ä‘á»ƒ vÄƒn báº£n Word Ä‘áº¹p hÆ¡n
        clean_text = line.strip().replace('**', '').replace('__', '')
        
        if not clean_text: continue
        
        if line.startswith('# '): 
            doc.add_heading(clean_text.replace('# ', ''), level=1)
        elif line.startswith('## '): 
            doc.add_heading(clean_text.replace('## ', ''), level=2)
        elif line.startswith('### '): 
            doc.add_heading(clean_text.replace('### ', ''), level=3)
        elif line.startswith('- ') or line.startswith('* '):
            doc.add_paragraph(clean_text[2:], style='List Bullet')
        else:
            doc.add_paragraph(clean_text)
    return doc

# --- 5. HÃ€M Xá»¬ LÃ Káº¾T QUáº¢ AN TOÃ€N (ANTI-CRASH) ---
def get_safe_response(response):
    """TrÃ­ch xuáº¥t text an toÃ n, xá»­ lÃ½ triá»‡t Ä‘á»ƒ lá»—i báº£n quyá»n (Finish Reason 4)"""
    try:
        if not response.candidates:
            return "\n\n[Lá»–I: KhÃ´ng cÃ³ pháº£n há»“i tá»« AI (Candidates Empty)]"
            
        finish_reason = response.candidates[0].finish_reason
        
        # 1: STOP (ThÃ nh cÃ´ng), 2: MAX_TOKENS (Háº¿t dung lÆ°á»£ng)
        if finish_reason in [1, 2]: 
            return response.text
        
        # 3: SAFETY (Bá»™ lá»c an toÃ n), 4: RECITATION (Báº£n quyá»n)
        elif finish_reason == 3:
            return "\n\n[Cáº¢NH BÃO: Ná»™i dung bá»‹ cháº·n do vi pháº¡m quy táº¯c an toÃ n cá»§a Google.]"
        elif finish_reason == 4:
            return "\n\n[Dá»ªNG: PhÃ¡t hiá»‡n ná»™i dung cÃ³ báº£n quyá»n/Ã¢m nháº¡c. Google tá»« chá»‘i xá»­ lÃ½ tiáº¿p.]"
        
        else:
            return f"\n\n[Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: Finish Reason {finish_reason}]"
            
    except Exception as e:
        try:
            return response.text # Cá»‘ gáº¯ng láº¥y text láº§n cuá»‘i
        except:
            return f"\n\n[Lá»—i xá»­ lÃ½ pháº£n há»“i: {e}]"

# --- 6. GIAO DIá»†N CHÃNH (MAIN) ---
def main():
    with st.sidebar:
        st.header("ğŸ¯ CHáº¾ Äá»˜")
        main_mode = st.radio("Má»¥c tiÃªu:", ("ğŸ“ Gá»¡ bÄƒng nguyÃªn vÄƒn", "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u"))
        
        if main_mode == "ğŸ“Š PhÃ¢n tÃ­ch chuyÃªn sÃ¢u":
            st.subheader("TÃ¹y chá»n output:")
            c1, c2 = st.columns(2)
            with c1:
                st.checkbox("ğŸ“‹ TÃ³m táº¯t", True)
                st.checkbox("âœ… HÃ nh Ä‘á»™ng", True)
            with c2:
                st.checkbox("ğŸ§  Mindmap", True)
                st.checkbox("â“ Quiz", False)
        else:
            st.info("Cháº¿ Ä‘á»™ Gá»¡ bÄƒng sáº½ tá»± Ä‘á»™ng cháº¡y ná»‘i tiáº¿p.")
            auto_continue = st.checkbox("Tá»± Ä‘á»™ng ná»‘i Ä‘oáº¡n (Auto-Loop)", value=True)
        
        st.divider()
        with st.expander("âš™ï¸ Cáº¥u hÃ¬nh & Key"):
            user_key = st.text_input("Key riÃªng (náº¿u cÃ³):", type="password")
            if configure_genai(user_key):
                st.success("ÄÃ£ káº¿t ná»‘i Gemini!")
                models = get_optimized_models()
                model_version = st.selectbox("Engine:", models, index=0)
            else: st.error("ChÆ°a káº¿t ná»‘i!")

        if st.button("ğŸ—‘ï¸ RESET & Dá»ŒN Dáº¸P"):
            cleanup_resources()
            st.session_state.clear()
            st.rerun()

    # --- TABS ---
    tab_work, tab_chat = st.tabs(["ğŸ“‚ Xá»­ lÃ½ File", "ğŸ’¬ Chat vá»›i AI"])

    with tab_work:
        if not st.session_state.is_auto_running:
            st.info("Há»— trá»£: Video, Ã‚m thanh, PDF, TÃ i liá»‡u. (Tá»± Ä‘á»™ng xÃ³a sau khi Reset)")
            up_files = st.file_uploader("Upload file", accept_multiple_files=True)
            audio_bytes = audio_recorder()

            if st.button("ğŸš€ Báº®T Äáº¦U Xá»¬ LÃ", type="primary"):
                # 1. LÆ°u file táº¡m (Local)
                temp_paths = []
                if up_files:
                    for f in up_files:
                        ext = os.path.splitext(f.name)[1] or ".txt"
                        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                            tmp.write(f.getvalue())
                            temp_paths.append(tmp.name)
                if audio_bytes:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(audio_bytes)
                        temp_paths.append(tmp.name)
                
                # LÆ°u Ä‘Æ°á»ng dáº«n local Ä‘á»ƒ xÃ³a sau nÃ y
                st.session_state.local_files.extend(temp_paths)

                if not temp_paths:
                    st.warning("Vui lÃ²ng chá»n file hoáº·c ghi Ã¢m!")
                else:
                    with st.spinner(f"Äang táº£i lÃªn Gemini ({model_version})..."):
                        try:
                            # 2. Upload lÃªn Gemini Cloud
                            g_files = [upload_to_gemini(p) for p in temp_paths]
                            st.session_state.gemini_files = g_files
                            
                            # Táº¯t bá»™ lá»c an toÃ n Ä‘á»ƒ trÃ¡nh lá»—i false positive
                            safety_settings = [
                                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                            ]
                            
                            gen_config = genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2)

                            # 3. Táº¡o Prompt ban Ä‘áº§u
                            if main_mode.startswith("ğŸ“"):
                                prompt = f"""
                                {STRICT_RULES}
                                NHIá»†M Vá»¤: Gá»¡ bÄƒng NGUYÃŠN VÄ‚N 100%.
                                YÃŠU Cáº¦U:
                                1. Báº¯t Ä‘áº§u má»—i cÃ¢u báº±ng [PhÃºt:GiÃ¢y].
                                2. Viáº¿t láº¡i chÃ­nh xÃ¡c tá»«ng tá»«, ká»ƒ cáº£ tá»« Ä‘á»‡m.
                                3. Äá»‹nh danh: 'Diá»…n giáº£ 1', 'Diá»…n giáº£ 2' (KhÃ´ng Ä‘oÃ¡n tÃªn tháº­t).
                                """
                                if auto_continue:
                                    st.session_state.is_auto_running = True
                                    st.session_state.loop_count = 1
                            else:
                                prompt = f"{STRICT_RULES}\nNHIá»†M Vá»¤: PhÃ¢n tÃ­ch sÃ¢u ná»™i dung.\nOUTPUT FORMAT:\n## TÃ“M Táº®T\n## HÃ€NH Äá»˜NG\n## MINDMAP (Mermaid code)\n## QUIZ"

                            # 4. Gá»i AI
                            model = genai.GenerativeModel(model_version)
                            response = model.generate_content(
                                [prompt] + g_files, 
                                generation_config=gen_config,
                                safety_settings=safety_settings
                            )
                            
                            safe_text = get_safe_response(response)
                            st.session_state.analysis_result = safe_text
                            st.rerun()
                        except Exception as e: st.error(f"Lá»—i khá»Ÿi táº¡o: {e}")

        # HIá»‚N THá»Š Káº¾T QUáº¢
        if st.session_state.analysis_result:
            # Logic dá»«ng náº¿u Ä‘ang auto-run
            if st.session_state.is_auto_running:
                st.warning(f"ğŸ”„ Äang tá»± Ä‘á»™ng ná»‘i Ä‘oáº¡n (VÃ²ng {st.session_state.loop_count}/{MAX_LOOPS})...")
                if st.button("ğŸ›‘ Dá»ªNG NGAY"):
                    st.session_state.is_auto_running = False
                    st.success("ÄÃ£ dá»«ng thá»§ cÃ´ng.")
                    st.rerun()

            st.divider()
            res = st.session_state.analysis_result
            
            # Render Mermaid náº¿u cÃ³
            if "```mermaid" in res:
                try:
                    m_code = res.split("```mermaid")[1].split("```")[0]
                    st_mermaid(m_code, height=500)
                except: pass
            
            # Hiá»ƒn thá»‹ Text trong Expander
            with st.expander("ğŸ“„ Ná»™i dung chi tiáº¿t", expanded=True):
                st.markdown(res)

            # NÃºt táº£i Word
            doc = create_docx(res)
            doc_io = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
            doc.save(doc_io.name)
            with open(doc_io.name, "rb") as f:
                st.download_button("ğŸ“¥ Táº£i BÃ¡o CÃ¡o (.docx)", f, "Bao_Cao_AI_Studio.docx", type="primary")
            os.remove(doc_io.name)

            # LOGIC AUTO-CONTINUE (LOOP)
            if st.session_state.is_auto_running and main_mode.startswith("ğŸ“"):
                # 1. Kiá»ƒm tra Ä‘iá»u kiá»‡n dá»«ng (Lá»—i hoáº·c Max Loops)
                if "[Dá»ªNG:" in res or "[Cáº¢NH BÃO:" in res:
                    st.session_state.is_auto_running = False
                    st.error("âš ï¸ Dá»«ng do váº¥n Ä‘á» báº£n quyá»n/an toÃ n.")
                elif st.session_state.loop_count >= MAX_LOOPS:
                    st.session_state.is_auto_running = False
                    st.warning(f"ğŸ›‘ ÄÃ£ Ä‘áº¡t giá»›i háº¡n {MAX_LOOPS} vÃ²ng láº·p. Dá»«ng Ä‘á»ƒ báº£o vá»‡ Quota.")
                else:
                    # 2. Chá» 2s Ä‘á»ƒ UI cáº­p nháº­t
                    time.sleep(2)
                    
                    with st.spinner("Äang nghe tiáº¿p Ä‘oáº¡n sau..."):
                        try:
                            # 3. Láº¥y má» neo thÃ´ng minh
                            last_part = get_smart_anchor(res)
                            
                            c_prompt = f"""
                            CONTEXT: Äang gá»¡ bÄƒng dá»Ÿ dang.
                            Má» NEO (Äoáº¡n cuá»‘i Ä‘Ã£ chÃ©p): "...{last_part}"
                            NHIá»†M Vá»¤: TÃ¬m vá»‹ trÃ­ má» neo trong file, chÃ©p tiáº¿p NGUYÃŠN VÄ‚N Ä‘oáº¡n ngay sau Ä‘Ã³. 
                            TUYá»†T Äá»I KHÃ”NG viáº¿t láº¡i Ä‘oáº¡n má» neo.
                            """
                            
                            model = genai.GenerativeModel(model_version)
                            # Sá»­ dá»¥ng config cÅ©
                            c_res = model.generate_content(
                                [c_prompt] + st.session_state.gemini_files, 
                                generation_config=genai.types.GenerationConfig(max_output_tokens=8192, temperature=0.2),
                                safety_settings=[{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"}] # RÃºt gá»n
                            )
                            
                            safe_c_text = get_safe_response(c_res)

                            # 4. Kiá»ƒm tra káº¿t quáº£ ná»‘i
                            if len(safe_c_text) < 50 or "káº¿t thÃºc" in safe_c_text.lower() or "[Dá»ªNG:" in safe_c_text:
                                st.session_state.is_auto_running = False
                                st.success("âœ… ÄÃ£ hoÃ n táº¥t (hoáº·c khÃ´ng cÃ²n ná»™i dung)!")
                                if len(safe_c_text) > 5:
                                    st.session_state.analysis_result += "\n\n" + safe_c_text
                                    st.rerun()
                            else:
                                st.session_state.analysis_result += "\n\n" + safe_c_text
                                st.session_state.loop_count += 1
                                st.rerun()
                        except Exception as e:
                            st.error(f"Lá»—i vÃ²ng láº·p: {e}")
                            st.session_state.is_auto_running = False

    with tab_chat:
        st.header("ğŸ’¬ Chat vá»›i dá»¯ liá»‡u")
        if st.session_state.gemini_files:
            for m in st.session_state.chat_history:
                with st.chat_message(m["role"]): st.markdown(m["content"])
            if inp := st.chat_input("Há»i AI vá» ná»™i dung file..."):
                st.session_state.chat_history.append({"role": "user", "content": inp})
                with st.chat_message("user"): st.markdown(inp)
                with st.chat_message("assistant"):
                    try:
                        m = genai.GenerativeModel(model_version)
                        r = m.generate_content(
                            st.session_state.gemini_files + [f"Tráº£ lá»i dá»±a trÃªn file: {inp}"]
                        )
                        st.markdown(r.text); st.session_state.chat_history.append({"role": "assistant", "content": r.text})
                    except: st.error("Lá»—i chat.")
        else: st.info("ğŸ‘ˆ Vui lÃ²ng Upload file á»Ÿ tab bÃªn cáº¡nh trÆ°á»›c.")

if __name__ == "__main__":
    main()
